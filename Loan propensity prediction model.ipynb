{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loan propensity prediction model\n",
    "### Peilun (Ann) Liu, Niaoniao Ma, Susannah Schulze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "import os\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.regression import linear_model\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LassoCV, LassoLarsCV, LassoLarsIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan</th>\n",
       "      <th>hh</th>\n",
       "      <th>village</th>\n",
       "      <th>religion</th>\n",
       "      <th>roof</th>\n",
       "      <th>rooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>electricity</th>\n",
       "      <th>ownership</th>\n",
       "      <th>leader</th>\n",
       "      <th>connections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1001</td>\n",
       "      <td>1</td>\n",
       "      <td>hindu</td>\n",
       "      <td>tile</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>OWNED</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1002</td>\n",
       "      <td>1</td>\n",
       "      <td>hindu</td>\n",
       "      <td>tile</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>OWNED</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1003</td>\n",
       "      <td>1</td>\n",
       "      <td>hindu</td>\n",
       "      <td>rcc</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>OWNED</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1004</td>\n",
       "      <td>1</td>\n",
       "      <td>hindu</td>\n",
       "      <td>tile</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>OWNED</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>hindu</td>\n",
       "      <td>tile</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>OWNED</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan    hh  village religion  roof  rooms  beds  electricity ownership  \\\n",
       "0     0  1001        1    hindu  tile      3     4            0     OWNED   \n",
       "1     0  1002        1    hindu  tile      1     1            1     OWNED   \n",
       "2     0  1003        1    hindu   rcc      3     4            1     OWNED   \n",
       "3     0  1004        1    hindu  tile      2     6            1     OWNED   \n",
       "4     0  1005        1    hindu  tile      3     4            1     OWNED   \n",
       "\n",
       "   leader  connections  \n",
       "0       0           10  \n",
       "1       1           14  \n",
       "2       1            4  \n",
       "3       0            8  \n",
       "4       0           16  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load data\n",
    "\n",
    "data = pd.read_csv(\"households_data.csv\", encoding='latin-1')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for nulls\n",
    "data.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan</th>\n",
       "      <th>village</th>\n",
       "      <th>rooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>electricity</th>\n",
       "      <th>leader</th>\n",
       "      <th>connections</th>\n",
       "      <th>christian</th>\n",
       "      <th>hindu</th>\n",
       "      <th>rcc</th>\n",
       "      <th>sheet</th>\n",
       "      <th>stone</th>\n",
       "      <th>thatch</th>\n",
       "      <th>tile</th>\n",
       "      <th>LEASED</th>\n",
       "      <th>OWNED</th>\n",
       "      <th>RENTED</th>\n",
       "      <th>SHARE_OWNED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   loan  village  rooms  beds  electricity  leader  connections  christian  \\\n",
       "0     0        1      3     4            0       0           10          0   \n",
       "1     0        1      1     1            1       1           14          0   \n",
       "2     0        1      3     4            1       1            4          0   \n",
       "3     0        1      2     6            1       0            8          0   \n",
       "4     0        1      3     4            1       0           16          0   \n",
       "\n",
       "   hindu  rcc  sheet  stone  thatch  tile  LEASED  OWNED  RENTED  SHARE_OWNED  \n",
       "0      1    0      0      0       0     1       0      1       0            0  \n",
       "1      1    0      0      0       0     1       0      1       0            0  \n",
       "2      1    1      0      0       0     0       0      1       0            0  \n",
       "3      1    0      0      0       0     1       0      1       0            0  \n",
       "4      1    0      0      0       0     1       0      1       0            0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating dummies\n",
    "rel_dummy = pd.get_dummies(data['religion']).iloc[:, 0:2]\n",
    "rm_dummy = pd.get_dummies(data['roof']).iloc[:, 1:]\n",
    "own_dummy = pd.get_dummies(data['ownership']).iloc[:, 1:]\n",
    "# Drop hh colums\n",
    "data_drop = data.drop(['hh', 'religion', 'roof', 'ownership'], axis =1)\n",
    "# Updating table\n",
    "table = pd.concat([data_drop, rel_dummy, rm_dummy, own_dummy], axis = 1)\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8622, 11)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8622, 18)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan</th>\n",
       "      <th>hh</th>\n",
       "      <th>village</th>\n",
       "      <th>rooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>electricity</th>\n",
       "      <th>leader</th>\n",
       "      <th>connections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8622.000000</td>\n",
       "      <td>8622.000000</td>\n",
       "      <td>8622.000000</td>\n",
       "      <td>8622.000000</td>\n",
       "      <td>8622.000000</td>\n",
       "      <td>8622.000000</td>\n",
       "      <td>8622.000000</td>\n",
       "      <td>8622.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.145558</td>\n",
       "      <td>41158.936906</td>\n",
       "      <td>41.038854</td>\n",
       "      <td>2.349107</td>\n",
       "      <td>0.867548</td>\n",
       "      <td>0.928671</td>\n",
       "      <td>0.117606</td>\n",
       "      <td>18.633496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.352683</td>\n",
       "      <td>21308.107236</td>\n",
       "      <td>21.306334</td>\n",
       "      <td>1.300611</td>\n",
       "      <td>1.403954</td>\n",
       "      <td>0.257389</td>\n",
       "      <td>0.322160</td>\n",
       "      <td>15.274832</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>1001.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>25097.250000</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>43029.500000</td>\n",
       "      <td>43.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>59078.750000</td>\n",
       "      <td>59.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>75172.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>180.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              loan            hh      village        rooms         beds  \\\n",
       "count  8622.000000   8622.000000  8622.000000  8622.000000  8622.000000   \n",
       "mean      0.145558  41158.936906    41.038854     2.349107     0.867548   \n",
       "std       0.352683  21308.107236    21.306334     1.300611     1.403954   \n",
       "min       0.000000   1001.000000     1.000000     0.000000     0.000000   \n",
       "25%       0.000000  25097.250000    25.000000     2.000000     0.000000   \n",
       "50%       0.000000  43029.500000    43.000000     2.000000     0.000000   \n",
       "75%       0.000000  59078.750000    59.000000     3.000000     1.000000   \n",
       "max       1.000000  75172.000000    75.000000    19.000000    50.000000   \n",
       "\n",
       "       electricity       leader  connections  \n",
       "count  8622.000000  8622.000000  8622.000000  \n",
       "mean      0.928671     0.117606    18.633496  \n",
       "std       0.257389     0.322160    15.274832  \n",
       "min       0.000000     0.000000     0.000000  \n",
       "25%       1.000000     0.000000     6.000000  \n",
       "50%       1.000000     0.000000    16.000000  \n",
       "75%       1.000000     0.000000    28.000000  \n",
       "max       1.000000     1.000000   180.000000  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan</th>\n",
       "      <th>hh</th>\n",
       "      <th>village</th>\n",
       "      <th>rooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>electricity</th>\n",
       "      <th>leader</th>\n",
       "      <th>connections</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.028468</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>-0.050608</td>\n",
       "      <td>-0.048439</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.048395</td>\n",
       "      <td>0.015696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hh</th>\n",
       "      <td>-0.028468</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>0.126128</td>\n",
       "      <td>-0.126510</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.014635</td>\n",
       "      <td>0.112225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>village</th>\n",
       "      <td>-0.028245</td>\n",
       "      <td>0.999994</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.126020</td>\n",
       "      <td>-0.126588</td>\n",
       "      <td>0.027453</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.112406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>-0.050608</td>\n",
       "      <td>0.126128</td>\n",
       "      <td>0.126020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420386</td>\n",
       "      <td>0.161366</td>\n",
       "      <td>0.111567</td>\n",
       "      <td>0.194857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>-0.048439</td>\n",
       "      <td>-0.126510</td>\n",
       "      <td>-0.126588</td>\n",
       "      <td>0.420386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107708</td>\n",
       "      <td>0.068810</td>\n",
       "      <td>0.113672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.027503</td>\n",
       "      <td>0.027453</td>\n",
       "      <td>0.161366</td>\n",
       "      <td>0.107708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046622</td>\n",
       "      <td>0.086493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leader</th>\n",
       "      <td>0.048395</td>\n",
       "      <td>0.014635</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.111567</td>\n",
       "      <td>0.068810</td>\n",
       "      <td>0.046622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connections</th>\n",
       "      <td>0.015696</td>\n",
       "      <td>0.112225</td>\n",
       "      <td>0.112406</td>\n",
       "      <td>0.194857</td>\n",
       "      <td>0.113672</td>\n",
       "      <td>0.086493</td>\n",
       "      <td>0.152643</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 loan        hh   village     rooms      beds  electricity  \\\n",
       "loan         1.000000 -0.028468 -0.028245 -0.050608 -0.048439     0.001940   \n",
       "hh          -0.028468  1.000000  0.999994  0.126128 -0.126510     0.027503   \n",
       "village     -0.028245  0.999994  1.000000  0.126020 -0.126588     0.027453   \n",
       "rooms       -0.050608  0.126128  0.126020  1.000000  0.420386     0.161366   \n",
       "beds        -0.048439 -0.126510 -0.126588  0.420386  1.000000     0.107708   \n",
       "electricity  0.001940  0.027503  0.027453  0.161366  0.107708     1.000000   \n",
       "leader       0.048395  0.014635  0.014577  0.111567  0.068810     0.046622   \n",
       "connections  0.015696  0.112225  0.112406  0.194857  0.113672     0.086493   \n",
       "\n",
       "               leader  connections  \n",
       "loan         0.048395     0.015696  \n",
       "hh           0.014635     0.112225  \n",
       "village      0.014577     0.112406  \n",
       "rooms        0.111567     0.194857  \n",
       "beds         0.068810     0.113672  \n",
       "electricity  0.046622     0.086493  \n",
       "leader       1.000000     0.152643  \n",
       "connections  0.152643     1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Looking at correlations\n",
    "data[data.columns[:]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan</th>\n",
       "      <th>village</th>\n",
       "      <th>rooms</th>\n",
       "      <th>beds</th>\n",
       "      <th>electricity</th>\n",
       "      <th>leader</th>\n",
       "      <th>connections</th>\n",
       "      <th>christian</th>\n",
       "      <th>hindu</th>\n",
       "      <th>rcc</th>\n",
       "      <th>sheet</th>\n",
       "      <th>stone</th>\n",
       "      <th>thatch</th>\n",
       "      <th>tile</th>\n",
       "      <th>LEASED</th>\n",
       "      <th>OWNED</th>\n",
       "      <th>RENTED</th>\n",
       "      <th>SHARE_OWNED</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>loan</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.028245</td>\n",
       "      <td>-0.050608</td>\n",
       "      <td>-0.048439</td>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.048395</td>\n",
       "      <td>0.015696</td>\n",
       "      <td>0.011329</td>\n",
       "      <td>-0.069555</td>\n",
       "      <td>-0.038993</td>\n",
       "      <td>-0.004572</td>\n",
       "      <td>-0.001454</td>\n",
       "      <td>0.007491</td>\n",
       "      <td>0.030038</td>\n",
       "      <td>0.006445</td>\n",
       "      <td>-0.011755</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>-0.000220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>village</th>\n",
       "      <td>-0.028245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.126020</td>\n",
       "      <td>-0.126588</td>\n",
       "      <td>0.027453</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.112406</td>\n",
       "      <td>-0.012476</td>\n",
       "      <td>0.049660</td>\n",
       "      <td>-0.011375</td>\n",
       "      <td>-0.037432</td>\n",
       "      <td>-0.098662</td>\n",
       "      <td>-0.005577</td>\n",
       "      <td>0.200901</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>0.041610</td>\n",
       "      <td>-0.048749</td>\n",
       "      <td>-0.054394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rooms</th>\n",
       "      <td>-0.050608</td>\n",
       "      <td>0.126020</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420386</td>\n",
       "      <td>0.161366</td>\n",
       "      <td>0.111567</td>\n",
       "      <td>0.194857</td>\n",
       "      <td>-0.010783</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>0.269557</td>\n",
       "      <td>-0.029222</td>\n",
       "      <td>-0.007919</td>\n",
       "      <td>-0.125343</td>\n",
       "      <td>-0.076312</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>0.062234</td>\n",
       "      <td>-0.081379</td>\n",
       "      <td>0.036702</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beds</th>\n",
       "      <td>-0.048439</td>\n",
       "      <td>-0.126588</td>\n",
       "      <td>0.420386</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.107708</td>\n",
       "      <td>0.068810</td>\n",
       "      <td>0.113672</td>\n",
       "      <td>-0.006013</td>\n",
       "      <td>0.012850</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>-0.001732</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>-0.071941</td>\n",
       "      <td>-0.084906</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>0.015375</td>\n",
       "      <td>-0.024756</td>\n",
       "      <td>0.029226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>electricity</th>\n",
       "      <td>0.001940</td>\n",
       "      <td>0.027453</td>\n",
       "      <td>0.161366</td>\n",
       "      <td>0.107708</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.046622</td>\n",
       "      <td>0.086493</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>-0.018841</td>\n",
       "      <td>0.070990</td>\n",
       "      <td>-0.003046</td>\n",
       "      <td>0.049134</td>\n",
       "      <td>-0.253088</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>0.011570</td>\n",
       "      <td>0.060664</td>\n",
       "      <td>-0.033067</td>\n",
       "      <td>-0.046181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>leader</th>\n",
       "      <td>0.048395</td>\n",
       "      <td>0.014577</td>\n",
       "      <td>0.111567</td>\n",
       "      <td>0.068810</td>\n",
       "      <td>0.046622</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.152643</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>0.010495</td>\n",
       "      <td>0.058117</td>\n",
       "      <td>-0.004666</td>\n",
       "      <td>0.021071</td>\n",
       "      <td>-0.025372</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>0.032076</td>\n",
       "      <td>-0.039589</td>\n",
       "      <td>0.004090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>connections</th>\n",
       "      <td>0.015696</td>\n",
       "      <td>0.112406</td>\n",
       "      <td>0.194857</td>\n",
       "      <td>0.113672</td>\n",
       "      <td>0.086493</td>\n",
       "      <td>0.152643</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.008114</td>\n",
       "      <td>0.057494</td>\n",
       "      <td>0.055472</td>\n",
       "      <td>-0.012463</td>\n",
       "      <td>-0.015110</td>\n",
       "      <td>-0.038813</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>-0.018859</td>\n",
       "      <td>0.054420</td>\n",
       "      <td>-0.070536</td>\n",
       "      <td>-0.014797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>christian</th>\n",
       "      <td>0.011329</td>\n",
       "      <td>-0.012476</td>\n",
       "      <td>-0.010783</td>\n",
       "      <td>-0.006013</td>\n",
       "      <td>0.007900</td>\n",
       "      <td>0.002234</td>\n",
       "      <td>-0.008114</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.123364</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>0.008816</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>-0.011824</td>\n",
       "      <td>-0.001190</td>\n",
       "      <td>-0.019222</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>-0.002688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hindu</th>\n",
       "      <td>-0.069555</td>\n",
       "      <td>0.049660</td>\n",
       "      <td>0.030720</td>\n",
       "      <td>0.012850</td>\n",
       "      <td>-0.018841</td>\n",
       "      <td>0.010495</td>\n",
       "      <td>0.057494</td>\n",
       "      <td>-0.123364</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>-0.021347</td>\n",
       "      <td>-0.020948</td>\n",
       "      <td>0.023880</td>\n",
       "      <td>0.024850</td>\n",
       "      <td>-0.041105</td>\n",
       "      <td>0.093689</td>\n",
       "      <td>-0.101579</td>\n",
       "      <td>-0.029121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rcc</th>\n",
       "      <td>-0.038993</td>\n",
       "      <td>-0.011375</td>\n",
       "      <td>0.269557</td>\n",
       "      <td>0.194909</td>\n",
       "      <td>0.070990</td>\n",
       "      <td>0.058117</td>\n",
       "      <td>0.055472</td>\n",
       "      <td>0.003082</td>\n",
       "      <td>0.006264</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.170848</td>\n",
       "      <td>-0.222852</td>\n",
       "      <td>-0.052541</td>\n",
       "      <td>-0.250799</td>\n",
       "      <td>-0.005686</td>\n",
       "      <td>0.034853</td>\n",
       "      <td>-0.024441</td>\n",
       "      <td>0.002807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sheet</th>\n",
       "      <td>-0.004572</td>\n",
       "      <td>-0.037432</td>\n",
       "      <td>-0.029222</td>\n",
       "      <td>-0.001732</td>\n",
       "      <td>-0.003046</td>\n",
       "      <td>-0.004666</td>\n",
       "      <td>-0.012463</td>\n",
       "      <td>-0.003584</td>\n",
       "      <td>-0.021347</td>\n",
       "      <td>-0.170848</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.310782</td>\n",
       "      <td>-0.073272</td>\n",
       "      <td>-0.349756</td>\n",
       "      <td>0.021984</td>\n",
       "      <td>-0.084108</td>\n",
       "      <td>0.055836</td>\n",
       "      <td>-0.017701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stone</th>\n",
       "      <td>-0.001454</td>\n",
       "      <td>-0.098662</td>\n",
       "      <td>-0.007919</td>\n",
       "      <td>0.001716</td>\n",
       "      <td>0.049134</td>\n",
       "      <td>0.021071</td>\n",
       "      <td>-0.015110</td>\n",
       "      <td>0.008816</td>\n",
       "      <td>-0.020948</td>\n",
       "      <td>-0.222852</td>\n",
       "      <td>-0.310782</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.095575</td>\n",
       "      <td>-0.456216</td>\n",
       "      <td>-0.008150</td>\n",
       "      <td>-0.000624</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>0.019386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>thatch</th>\n",
       "      <td>0.007491</td>\n",
       "      <td>-0.005577</td>\n",
       "      <td>-0.125343</td>\n",
       "      <td>-0.071941</td>\n",
       "      <td>-0.253088</td>\n",
       "      <td>-0.025372</td>\n",
       "      <td>-0.038813</td>\n",
       "      <td>0.023460</td>\n",
       "      <td>0.023880</td>\n",
       "      <td>-0.052541</td>\n",
       "      <td>-0.073272</td>\n",
       "      <td>-0.095575</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.107560</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>-0.027332</td>\n",
       "      <td>0.002749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tile</th>\n",
       "      <td>0.030038</td>\n",
       "      <td>0.200901</td>\n",
       "      <td>-0.076312</td>\n",
       "      <td>-0.084906</td>\n",
       "      <td>0.008222</td>\n",
       "      <td>-0.038781</td>\n",
       "      <td>0.007715</td>\n",
       "      <td>-0.011824</td>\n",
       "      <td>0.024850</td>\n",
       "      <td>-0.250799</td>\n",
       "      <td>-0.349756</td>\n",
       "      <td>-0.456216</td>\n",
       "      <td>-0.107560</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.012278</td>\n",
       "      <td>0.052134</td>\n",
       "      <td>-0.026032</td>\n",
       "      <td>-0.030881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LEASED</th>\n",
       "      <td>0.006445</td>\n",
       "      <td>-0.017189</td>\n",
       "      <td>0.001634</td>\n",
       "      <td>-0.002009</td>\n",
       "      <td>0.011570</td>\n",
       "      <td>0.002038</td>\n",
       "      <td>-0.018859</td>\n",
       "      <td>-0.001190</td>\n",
       "      <td>-0.041105</td>\n",
       "      <td>-0.005686</td>\n",
       "      <td>0.021984</td>\n",
       "      <td>-0.008150</td>\n",
       "      <td>0.012691</td>\n",
       "      <td>-0.012278</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.131628</td>\n",
       "      <td>-0.009611</td>\n",
       "      <td>-0.003937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>OWNED</th>\n",
       "      <td>-0.011755</td>\n",
       "      <td>0.041610</td>\n",
       "      <td>0.062234</td>\n",
       "      <td>0.015375</td>\n",
       "      <td>0.060664</td>\n",
       "      <td>0.032076</td>\n",
       "      <td>0.054420</td>\n",
       "      <td>-0.019222</td>\n",
       "      <td>0.093689</td>\n",
       "      <td>0.034853</td>\n",
       "      <td>-0.084108</td>\n",
       "      <td>-0.000624</td>\n",
       "      <td>0.003742</td>\n",
       "      <td>0.052134</td>\n",
       "      <td>-0.131628</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.725913</td>\n",
       "      <td>-0.297340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RENTED</th>\n",
       "      <td>0.001245</td>\n",
       "      <td>-0.048749</td>\n",
       "      <td>-0.081379</td>\n",
       "      <td>-0.024756</td>\n",
       "      <td>-0.033067</td>\n",
       "      <td>-0.039589</td>\n",
       "      <td>-0.070536</td>\n",
       "      <td>0.012062</td>\n",
       "      <td>-0.101579</td>\n",
       "      <td>-0.024441</td>\n",
       "      <td>0.055836</td>\n",
       "      <td>-0.006073</td>\n",
       "      <td>-0.027332</td>\n",
       "      <td>-0.026032</td>\n",
       "      <td>-0.009611</td>\n",
       "      <td>-0.725913</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.021711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SHARE_OWNED</th>\n",
       "      <td>-0.000220</td>\n",
       "      <td>-0.054394</td>\n",
       "      <td>0.036702</td>\n",
       "      <td>0.029226</td>\n",
       "      <td>-0.046181</td>\n",
       "      <td>0.004090</td>\n",
       "      <td>-0.014797</td>\n",
       "      <td>-0.002688</td>\n",
       "      <td>-0.029121</td>\n",
       "      <td>0.002807</td>\n",
       "      <td>-0.017701</td>\n",
       "      <td>0.019386</td>\n",
       "      <td>0.002749</td>\n",
       "      <td>-0.030881</td>\n",
       "      <td>-0.003937</td>\n",
       "      <td>-0.297340</td>\n",
       "      <td>-0.021711</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 loan   village     rooms      beds  electricity    leader  \\\n",
       "loan         1.000000 -0.028245 -0.050608 -0.048439     0.001940  0.048395   \n",
       "village     -0.028245  1.000000  0.126020 -0.126588     0.027453  0.014577   \n",
       "rooms       -0.050608  0.126020  1.000000  0.420386     0.161366  0.111567   \n",
       "beds        -0.048439 -0.126588  0.420386  1.000000     0.107708  0.068810   \n",
       "electricity  0.001940  0.027453  0.161366  0.107708     1.000000  0.046622   \n",
       "leader       0.048395  0.014577  0.111567  0.068810     0.046622  1.000000   \n",
       "connections  0.015696  0.112406  0.194857  0.113672     0.086493  0.152643   \n",
       "christian    0.011329 -0.012476 -0.010783 -0.006013     0.007900  0.002234   \n",
       "hindu       -0.069555  0.049660  0.030720  0.012850    -0.018841  0.010495   \n",
       "rcc         -0.038993 -0.011375  0.269557  0.194909     0.070990  0.058117   \n",
       "sheet       -0.004572 -0.037432 -0.029222 -0.001732    -0.003046 -0.004666   \n",
       "stone       -0.001454 -0.098662 -0.007919  0.001716     0.049134  0.021071   \n",
       "thatch       0.007491 -0.005577 -0.125343 -0.071941    -0.253088 -0.025372   \n",
       "tile         0.030038  0.200901 -0.076312 -0.084906     0.008222 -0.038781   \n",
       "LEASED       0.006445 -0.017189  0.001634 -0.002009     0.011570  0.002038   \n",
       "OWNED       -0.011755  0.041610  0.062234  0.015375     0.060664  0.032076   \n",
       "RENTED       0.001245 -0.048749 -0.081379 -0.024756    -0.033067 -0.039589   \n",
       "SHARE_OWNED -0.000220 -0.054394  0.036702  0.029226    -0.046181  0.004090   \n",
       "\n",
       "             connections  christian     hindu       rcc     sheet     stone  \\\n",
       "loan            0.015696   0.011329 -0.069555 -0.038993 -0.004572 -0.001454   \n",
       "village         0.112406  -0.012476  0.049660 -0.011375 -0.037432 -0.098662   \n",
       "rooms           0.194857  -0.010783  0.030720  0.269557 -0.029222 -0.007919   \n",
       "beds            0.113672  -0.006013  0.012850  0.194909 -0.001732  0.001716   \n",
       "electricity     0.086493   0.007900 -0.018841  0.070990 -0.003046  0.049134   \n",
       "leader          0.152643   0.002234  0.010495  0.058117 -0.004666  0.021071   \n",
       "connections     1.000000  -0.008114  0.057494  0.055472 -0.012463 -0.015110   \n",
       "christian      -0.008114   1.000000 -0.123364  0.003082 -0.003584  0.008816   \n",
       "hindu           0.057494  -0.123364  1.000000  0.006264 -0.021347 -0.020948   \n",
       "rcc             0.055472   0.003082  0.006264  1.000000 -0.170848 -0.222852   \n",
       "sheet          -0.012463  -0.003584 -0.021347 -0.170848  1.000000 -0.310782   \n",
       "stone          -0.015110   0.008816 -0.020948 -0.222852 -0.310782  1.000000   \n",
       "thatch         -0.038813   0.023460  0.023880 -0.052541 -0.073272 -0.095575   \n",
       "tile            0.007715  -0.011824  0.024850 -0.250799 -0.349756 -0.456216   \n",
       "LEASED         -0.018859  -0.001190 -0.041105 -0.005686  0.021984 -0.008150   \n",
       "OWNED           0.054420  -0.019222  0.093689  0.034853 -0.084108 -0.000624   \n",
       "RENTED         -0.070536   0.012062 -0.101579 -0.024441  0.055836 -0.006073   \n",
       "SHARE_OWNED    -0.014797  -0.002688 -0.029121  0.002807 -0.017701  0.019386   \n",
       "\n",
       "               thatch      tile    LEASED     OWNED    RENTED  SHARE_OWNED  \n",
       "loan         0.007491  0.030038  0.006445 -0.011755  0.001245    -0.000220  \n",
       "village     -0.005577  0.200901 -0.017189  0.041610 -0.048749    -0.054394  \n",
       "rooms       -0.125343 -0.076312  0.001634  0.062234 -0.081379     0.036702  \n",
       "beds        -0.071941 -0.084906 -0.002009  0.015375 -0.024756     0.029226  \n",
       "electricity -0.253088  0.008222  0.011570  0.060664 -0.033067    -0.046181  \n",
       "leader      -0.025372 -0.038781  0.002038  0.032076 -0.039589     0.004090  \n",
       "connections -0.038813  0.007715 -0.018859  0.054420 -0.070536    -0.014797  \n",
       "christian    0.023460 -0.011824 -0.001190 -0.019222  0.012062    -0.002688  \n",
       "hindu        0.023880  0.024850 -0.041105  0.093689 -0.101579    -0.029121  \n",
       "rcc         -0.052541 -0.250799 -0.005686  0.034853 -0.024441     0.002807  \n",
       "sheet       -0.073272 -0.349756  0.021984 -0.084108  0.055836    -0.017701  \n",
       "stone       -0.095575 -0.456216 -0.008150 -0.000624 -0.006073     0.019386  \n",
       "thatch       1.000000 -0.107560  0.012691  0.003742 -0.027332     0.002749  \n",
       "tile        -0.107560  1.000000 -0.012278  0.052134 -0.026032    -0.030881  \n",
       "LEASED       0.012691 -0.012278  1.000000 -0.131628 -0.009611    -0.003937  \n",
       "OWNED        0.003742  0.052134 -0.131628  1.000000 -0.725913    -0.297340  \n",
       "RENTED      -0.027332 -0.026032 -0.009611 -0.725913  1.000000    -0.021711  \n",
       "SHARE_OWNED  0.002749 -0.030881 -0.003937 -0.297340 -0.021711     1.000000  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "table[table.columns[:]].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2054b9d9fa0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXl0lEQVR4nO3df5TddX3n8edrZoCiMV25jGkIhEGT4oEqUWbZ7ra6qBkYsEKlK5JjZaruRs8pCWLP7qrbnmpLPXuq6JKspQ3HlIlHUVpkTQpMmHBaOK22OsGUhF9lwAETYjLetBCIRmbmvX/c73xzE+6Em2G+9zOZ7+txzj33fj7f73e+bzj35HU/3x+fryICMzMzgLbUBZiZ2ezhUDAzs5xDwczMcg4FMzPLORTMzCzXkbqAV+LUU0+Nrq6u1GWYmR1Xtm7d+pOI6Gy07LgOha6uLoaGhlKXYWZ2XJH01FTLfPjIzMxyDgUzM8s5FMzMLOdQMDOznEPBAKhWq6xevZpqtZq6FDNLyKFgAPT397N9+3Y2bNiQuhQzS8ihYFSrVQYGBogIBgYGPFowKzGHgtHf38/ExAQA4+PjHi2YlZhDwdiyZQtjY2MAjI2NMTg4mLgiM0vFoWAsX76cjo7aze0dHR309PQkrsjMUnEoGH19fbS11b4K7e3tXH311YkrMrNUCgsFSesl7ZW0o67vm5K2Za8RSduy/i5JP61b9udF1WUvValU6O3tRRK9vb1UKpXUJZlZIkVOiHcL8H+B/KxlRLx/8rOkG4Bn69Z/IiKWFViPHUVfXx8jIyMeJZiVXGGhEBH3S+pqtEySgCuBdxa1fzs2lUqFNWvWpC7DzBJLdU7hbcCeiHi8ru8sST+QdJ+kt021oaSVkoYkDY2OjhZfqZlZiaQKhRXArXXt3cDiiHgL8Ang65LmN9owItZFRHdEdHd2NnxGhJmZTVPLQ0FSB3AF8M3Jvog4GBHV7PNW4Angl1tdm5lZ2aUYKSwHHo2InZMdkjoltWefXw8sBZ5MUJuZWakVeUnqrcB3gbMl7ZT0kWzRVRx+6Ajg7cCDkv4Z+GvgYxGxr6jazMyssSKvPloxRf/vNOi7Hbi9qFrMzKw5vqPZzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FAyoPad59erVfj6zWck5FAyoPad5+/btfj6zWck5FIxqtcrAwAARwcDAgEcLZiXmUDD6+/uZmJgAYHx83KMFsxJzKBhbtmxhbGwMgLGxMQYHBxNXZGapOBSM5cuX09FRmwaro6ODnp6exBWZWSoOBaOvr4+2ttpXob293c9pNisxh4JRqVTo7e1FEr29vVQqldQlmVkihU2dbceXvr4+RkZGPEowKzmHggG10cKaNWtSl2FmifnwkZmZ5RwKZmaWK/IZzesl7ZW0o67vM5J2SdqWvS6tW/YpScOSHpN0cVF1mZnZ1IocKdwC9Dbo/1JELMtedwFIOge4Cjg32+bPJLUXWJuZmTVQWChExP3AviZXvxz4RkQcjIgfAsPABUXVZmZmjaU4p3CNpAezw0uvzfoWAT+qW2dn1vcSklZKGpI0NDo6WnStZmal0upQuAl4A7AM2A3ckPWrwbrR6A9ExLqI6I6I7s7OzmKqNDMrqZaGQkTsiYjxiJgAbubQIaKdwBl1q54OPNPK2szMrMWhIGlhXfO9wOSVSRuBqySdJOksYCnwvVbWZmZmBd7RLOlW4ELgVEk7gT8ELpS0jNqhoRHgowAR8ZCk24CHgTHgdyNivKjazMysMUU0PHR/XOju7o6hoaHUZZiZHVckbY2I7kbLfEezmZnlHApmZpZzKJiZWc6hYGZmOYeCmZnlHApmZpZzKJiZWc6hYGZmOYeCmZnlHApmZpZzKJiZWc6hYGZmOYeCmZnlHApmZpZzKJiZWc6hYGZmOYeCmZnlHApmZpYrLBQkrZe0V9KOur7PS3pU0oOS7pD077L+Lkk/lbQte/15UXWZmdnUihwp3AL0HtE3CPxKRLwZ+BfgU3XLnoiIZdnrYwXWZWZmUygsFCLifmDfEX33RMRY1vxH4PSi9m9mZscu5TmFDwN317XPkvQDSfdJeluqoszMyqwjxU4l/S9gDPha1rUbWBwRVUnnA/9P0rkR8VyDbVcCKwEWL17cqpLNzEqh5SMFSX3AbwAfiIgAiIiDEVHNPm8FngB+udH2EbEuIrojoruzs7NVZZuZlUJLQ0FSL/A/gcsi4kBdf6ek9uzz64GlwJOtrM3MzAo8fCTpVuBC4FRJO4E/pHa10UnAoCSAf8yuNHo78EeSxoBx4GMRsa/hHzYzs8IUFgoRsaJB91emWPd24PaiajEzs+b4jmYzM8s5FAyAarXK6tWrqVarqUsxs4QcCgZAf38/27dvZ8OGDalLMbOEHApGtVrl7rvvJiK4++67PVowKzGHgtHf38/YWG32kRdffNGjBbMScygYg4ODZPcREhHcc889iSsys1SaCgVJ75P0muzz70v6lqS3FluatcqCBQuO2jaz8mh2pPAHEbFf0q8DFwP9wE3FlWWttGfPnqO2zaw8mg2F8ez93cBNEfFt4MRiSrJW6+npOax90UUXJarEzFJrNhR2SfoL4ErgLkknHcO2Nstddtllh7Xf8573JKrEzFJr9h/2K4HNQG9E/BtwCvDfC6vKWmrjxo1kc1EhiU2bNiWuyMxSaSoUshlNvw28IGkxcALwaJGFWets2bLlsKuPBgcHE1dkZqk0e/XRKmAPtWcs35m9/qbAuqyFli9fTkdHbW7Ejo6Ol5xjMLPyaPbw0bXA2RFxbkS8KXu9ucjCrHX6+vpoa6t9Fdrb27n66qsTV2RmqTQbCj8Cni2yEEunUqnQ29uLJHp7e6lUKqlLMrNEmn2ewpPA30m6Ezg42RkRXyykKmu5vr4+RkZGPEowK7lmQ+Hp7HUivj9hTqpUKqxZsyZ1GWaWWFOhEBGfBcimuoiIeL7QqszMLIlmrz76FUk/AHYAD0naKuncYkuzVvJDdswMmj/RvA74REScGRFnAr8H3Hy0DSStl7RX0o66vlMkDUp6PHt/bd2yT0kalvSYpIun8x9j0+eH7JgZNB8Kr46Iv51sRMTfAa9+mW1uAXqP6PskcG9ELAXuzdpIOge4Cjg32+bPJLU3WZu9Qn7IjplNajYUnpT0B5K6stfvAz882gYRcT+w74juy6nNsEr2/pt1/d+IiIMR8UNgGLigydrsFfJDdsxsUrOh8GGgE/gWcEf2+UPT2N+CiNgNkL2/LutfRO1eiEk7s76XkLRS0pCkodHR0WmUYEfyQ3bMbFKzVx/9K7C6wDrUaLdT1LKO2jkOuru7G65jx2bBggWMjIwc1jazcjpqKEj6PxHxcUmbaPCPdERc1mCzo9kjaWFE7Ja0ENib9e8Ezqhb73TgmWP82zZNfsiOmU16uZHCV7P3L8zQ/jYCfcD/zt6/Xdf/dUlfBE4DlgLfm6F92svo6elh48aNedsP2TErr6OeU4iIrdnHZRFxX/0LWHa0bSXdCnwXOFvSTkkfoRYGPZIeB3qyNhHxEHAb8DAwAPxuRIw3/ss20+onxGtra/NUF2Yl1uw0F33AjUf0/U6DvlxErJhi0bumWP9PgD9psh4zMyvAUUcKklZk5xPOkrSx7vW3gC9mnyP6+/uZmJgAYGJiwpekmpXYy40UvgPsBk4Fbqjr3w88WFRR1lpHXoK6efNmrrvuukTVmFlKRw2FiHgKeErSB4BnIuJnAJJOpnaF0EjhFVrhJp+6NlXbzMqj2ZvXbgMm6trjwF/NfDmWwvPPP3/UtpmVR7Oh0BERP59sZJ/9XIU5wiMFM5vUbCiMSspvVJN0OfCTYkqyVpuc92iqtpmVR7M/CT8GfE3Sl6nd2bwT8MXsZmZzTLNzHz0B/KqkeYAiYn+xZZmZWQrNPnltgaSvAH8VEfslnZPdoWxmZnNIs+cUbgE2U5uXCOBfgI8XUZCZmaXTbCicGhH5ZakRMUbtslSbAxYuXHhY+7TTTptiTbPWGx4e5t3vfjfDw8OpSymFZkPhBUkVsumzJf0q8GxhVVlSkw/cMZsNrr/+el544QWuv/761KWUQrOh8Alq01u/QdI/ABuAVYVVZS21e/fuo7bNUhkeHs4fADUyMuLRQgs0FQoR8QDwn4H/BHwUODciPPeRmRXqyNGBRwvFO5ZbVy8AurJt3iqJiPB0mmZWmPrHxDZq28xrKhQkfRV4A7CNQyeYg9phJDOzQsybN++wubjmzZuXsJpyaHak0A2cEz4DaWYt5ClYWq/ZE807gF8qshAzsyMd+bzwiy++OFEl5dH0fQrAw5I21z+BbTo7lHS2pG11r+ckfVzSZyTtquu/dDp/38zmjr6+Pk444QQATjjhBD8/vAWaPXz0mZnaYUQ8BiwDkNQO7ALuAD4EfCkivjBT+zKz41ulUuGSSy5h06ZNXHrppVQqldQlzXnNToh3X0H7fxfwREQ8JamgXZjZ8ayvr4+RkRGPElqk2QnxrpD0uKRns8M9+yU9NwP7vwq4ta59jaQHJa2X9NoZ+PtmdpyrVCqsWbPGo4QWafacwp8Cl0XEL0bE/Ih4TUTMfyU7lnQicBmHHut5E7XLXpcBu4EbpthupaQhSUOjo6OvpAQzMztCs6GwJyIemeF9XwI8EBF7ACJiT0SMR8QEcDO1m+VeIiLWRUR3RHR3dnbOcElmNttUq1VWr15NtVpNXUopNBsKQ5K+KWlFdijpCklXvMJ9r6Du0JGk+qk630vtMlgzK7n+/n62b9/Ohg2+V7YVmg2F+cAB4CLgPdnrN6a7U0mvAnqAb9V1/6mk7ZIeBN4BXDfdv29mc0O1WmVgYICIYGBgwKOFFmj26qMPzeROI+IAUDmi74MzuQ8zO/719/czMTEBwPj4OBs2bOC66/x7sUjNXn10uqQ7JO2VtEfS7ZJOL7o4Myu3LVu25FNbjI2NMTg4mLiiua/Zw0d/Se15CqcBi4BNWZ+ZWWGWL19OR0ftgEZHRwc9PT2JK5r7mg2Fzoj4y4gYy163AL70x8wK1dfXR1tb7Z+p9vZ238DWAs2Gwk8k/bak9uz124DP+JhZoSqVCr29vUiit7fXN7C1QLOh8GHgSuDH1G4s+y/U5ioyMytUX18fb3rTmzxKaJFmJ8T7Y6AvIv4VQNIpwBeohYWZmc0RzY4U3jwZCAARsQ94SzElmZkd4pvXWqvZUGirn6AuGykcy/OdzcyOWbVa5a677iIiuPPOO33zWgs0Gwo3AN+R9MeS/gj4DrVJ8szMCtPf33/YfQoeLRSvqVCIiA3AbwF7gFHgioj4apGFmZlt3rz5sPbAwECiSsqj6UNAEfEw8HCBtZTW2rVrGR4eTl3GYa699tpk+16yZAmrVq1Ktn+bPcbHx4/atpnX7OEjm8NOOumko7bNUpk8dDRV22aeTxbPArPhV/GFF16Yfz5yyG7llXoU29bWlk+IN9n2KLZYHikYcGh08MY3vjFxJWaHnHnmmYe1u7q60hRSIh4pGHAoDG688cbEldhsMht+Fb/zne9kYmKCefPmsX79+tTlzHkeKZjZrDY5WvjsZz+buJJycCiY2aw2f/58zjvvPM4///zUpZSCQ8HMzHIOBTMzyyU50SxpBNgPjANjEdGdzaf0TaALGAGurJ+Ez8zMipdypPCOiFgWEd1Z+5PAvRGxFLg3a5uZWQvNpsNHlwP92ed+4DcT1mJmVkqpQiGAeyRtlbQy61sQEbsBsvfXNdpQ0kpJQ5KGRkdHW1SumVk5pLp57dci4hlJrwMGJT3a7IYRsQ5YB9Dd3R1FFWhmVkZJRgoR8Uz2vhe4A7gA2CNpIUD2vjdFbWZmZdbyUJD0akmvmfwMXATsADYCfdlqfcC3W12bmVnZpTh8tAC4Q9Lk/r8eEQOSvg/cJukjwNPA+xLUZmZWai0PhYh4EjivQX8VeFer6zEzs0Nm0yWpZmaWmEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznEPBzMxyDgUzM8s5FMzMLOdQMDOznCIidQ3T1t3dHUNDQ9Pefu3atQwPD89gRcevyf8PS5YsSVzJ7LBkyRJWrVqVbP/+bh7i7+bhZuK7KWlrRHQ3Wtbyx3FKOgPYAPwSMAGsi4gbJX0G+G/AaLbqpyPiriJrGR4eZtuORxh/1SlF7ua40Pbz2o+DrU/uSVxJeu0H9qUugeHhYR5/6AcsnjeeupTkTnyxdkDj4FPT/wE4Vzz9fHvh+2h5KABjwO9FxAOSXgNslTSYLftSRHyhlcWMv+oUfvrGS1u5S5vlTn600N8iTVs8b5xPv/W51GXYLPK5B+YXvo+Wh0JE7AZ2Z5/3S3oEWNTqOszM7KWSnmiW1AW8BfinrOsaSQ9KWi/ptVNss1LSkKSh0dHRRquYmdk0JQsFSfOA24GPR8RzwE3AG4Bl1EYSNzTaLiLWRUR3RHR3dna2rF4zszJIEgqSTqAWCF+LiG8BRMSeiBiPiAngZuCCFLWZmZVZy0NBkoCvAI9ExBfr+hfWrfZeYEerazMzK7sUVx/9GvBBYLukbVnfp4EVkpYBAYwAH01Qm5lZqaW4+ujvATVYNDuuAzQzKzFPc2FmZjmHgpmZ5RwKZmaWS3Gi2cxexq5du3hhf3tLpjWw48dT+9t59a5dhe7DIwUzM8t5pGA2Cy1atIiDY7s9IZ4d5nMPzOekRcVOFVfqUNi1axftB56dNbNi2uzQfqDKrl1jqcswS8KHj8zMLFfqkcKiRYv48cEOP0/BDnPyo3exaNGC1GWYJeGRgpmZ5RwKZmaWcyiYmVmu1OcUzGazp5/3zWsAew7UfrsueNVE4krSe/r5dpYWvA+HgtkstGTJktQlzBo/Hx4G4KQz/f9kKcV/N0ofCu0H9vk+BaDtZ7WbpCZ+wb9M2w/sA9JefbRq1aqk+59Nrr32WgBuvPHGxJWUQ6lDwb/GDhke3g/Aktf7UkxY4O+GlVapQ8G/xg7xrzEzA199ZGZmdRwKZmaWm3WhIKlX0mOShiV9MnU9ZmZlMqtCQVI78GXgEuAcYIWkc9JWZWZWHrPtRPMFwHBEPAkg6RvA5cDDSasq2Nq1axnOrsVOZXL/kyecU1qyZIkvApgl/N08XBm+m7MtFBYBP6pr7wT+Q/0KklYCKwEWL17cusrmuJNPPjl1CWYN+bvZWoqI1DXkJL0PuDgi/mvW/iBwQUQ0jObu7u4YGhpqZYlmZsc9SVsjorvRsll1ToHayOCMuvbpwDOJajEzK53ZFgrfB5ZKOkvSicBVwMbENZmZlcasOqcQEWOSrgE2A+3A+oh4KHFZZmalMatCASAi7gI8Q52ZWQKz7fCRmZkl5FAwM7OcQ8HMzHIOBTMzy82qm9eOlaRR4KnUdcwhpwI/SV2EWQP+bs6sMyOis9GC4zoUbGZJGprqLkezlPzdbB0fPjIzs5xDwczMcg4Fq7cudQFmU/B3s0V8TsHMzHIeKZiZWc6hYGZmOYeCIalX0mOShiV9MnU9ZpMkrZe0V9KO1LWUhUOh5CS1A18GLgHOAVZIOidtVWa5W4De1EWUiUPBLgCGI+LJiPg58A3g8sQ1mQEQEfcD+1LXUSYOBVsE/KiuvTPrM7MSciiYGvT5OmWzknIo2E7gjLr26cAziWoxs8QcCvZ9YKmksySdCFwFbExck5kl4lAouYgYA64BNgOPALdFxENpqzKrkXQr8F3gbEk7JX0kdU1znae5MDOznEcKZmaWcyiYmVnOoWBmZjmHgpmZ5RwKZmaWcyiYHSNJz6euwawoDgUzM8s5FMymSTWfl7RD0nZJ78/650m6V9IDWf/lWX+XpEck3SzpIUn3SDo57X+F2eEcCmbTdwWwDDgPWA58XtJC4GfAeyPircA7gBskTU48uBT4ckScC/wb8FutL9tsag4Fs+n7deDWiBiPiD3AfcC/pzbz7OckPQhsoTYV+YJsmx9GxLbs81agq7Ulmx1dR+oCzI5jjaYdB/gA0AmcHxEvShoBfiFbdrBuvXHAh49sVvFIwWz67gfeL6ldUifwduB7wC8Ce7NAeAdwZsoizY6FRwpm03cH8B+Bf6b2YKL/ERE/lvQ1YJOkIWAb8GjCGs2OiWdJNTOznA8fmZlZzqFgZmY5h4KZmeUcCmZmlnMomJlZzqFgZmY5h4KZmeX+P22NFhv+vejdAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Looking at variable relationships through basic plot\n",
    "loan = table['loan']\n",
    "conn = table['connections']\n",
    "data_plot = pd.concat([conn, loan], axis =1)\n",
    "sns.boxplot( x=table[\"loan\"], y=table[\"connections\"] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(table.rooms, table.beds, '.', color='black')\n",
    "plt.xlabel('Rooms')\n",
    "plt.ylabel('Beds');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>loan</td>       <th>  R-squared (uncentered):</th>      <td>   0.151</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.150</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   90.24</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 16 Feb 2021</td> <th>  Prob (F-statistic):</th>          <td>2.60e-290</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:48:09</td>     <th>  Log-Likelihood:    </th>          <td> -3218.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8622</td>      <th>  AIC:               </th>          <td>   6472.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8605</td>      <th>  BIC:               </th>          <td>   6592.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    17</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>village</th>     <td>   -0.0005</td> <td>    0.000</td> <td>   -2.407</td> <td> 0.016</td> <td>   -0.001</td> <td>-8.43e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rooms</th>       <td>   -0.0063</td> <td>    0.003</td> <td>   -1.838</td> <td> 0.066</td> <td>   -0.013</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>beds</th>        <td>   -0.0105</td> <td>    0.003</td> <td>   -3.432</td> <td> 0.001</td> <td>   -0.016</td> <td>   -0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>electricity</th> <td>    0.0572</td> <td>    0.015</td> <td>    3.946</td> <td> 0.000</td> <td>    0.029</td> <td>    0.086</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leader</th>      <td>    0.0583</td> <td>    0.012</td> <td>    4.870</td> <td> 0.000</td> <td>    0.035</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>connections</th> <td>    0.0007</td> <td>    0.000</td> <td>    2.809</td> <td> 0.005</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>christian</th>   <td>    0.0939</td> <td>    0.134</td> <td>    0.701</td> <td> 0.483</td> <td>   -0.169</td> <td>    0.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>hindu</th>       <td>   -0.0437</td> <td>    0.016</td> <td>   -2.809</td> <td> 0.005</td> <td>   -0.074</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rcc</th>         <td>    0.0482</td> <td>    0.020</td> <td>    2.415</td> <td> 0.016</td> <td>    0.009</td> <td>    0.087</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sheet</th>       <td>    0.0794</td> <td>    0.017</td> <td>    4.548</td> <td> 0.000</td> <td>    0.045</td> <td>    0.114</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>stone</th>       <td>    0.0778</td> <td>    0.017</td> <td>    4.599</td> <td> 0.000</td> <td>    0.045</td> <td>    0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>thatch</th>      <td>    0.1193</td> <td>    0.030</td> <td>    4.029</td> <td> 0.000</td> <td>    0.061</td> <td>    0.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>tile</th>        <td>    0.0975</td> <td>    0.017</td> <td>    5.714</td> <td> 0.000</td> <td>    0.064</td> <td>    0.131</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LEASED</th>      <td>    0.1187</td> <td>    0.092</td> <td>    1.285</td> <td> 0.199</td> <td>   -0.062</td> <td>    0.300</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OWNED</th>       <td>    0.0759</td> <td>    0.018</td> <td>    4.298</td> <td> 0.000</td> <td>    0.041</td> <td>    0.110</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RENTED</th>      <td>    0.0793</td> <td>    0.023</td> <td>    3.401</td> <td> 0.001</td> <td>    0.034</td> <td>    0.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SHARE_OWNED</th> <td>    0.0967</td> <td>    0.043</td> <td>    2.233</td> <td> 0.026</td> <td>    0.012</td> <td>    0.182</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2900.913</td> <th>  Durbin-Watson:     </th> <td>   1.685</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6988.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.969</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.986</td>  <th>  Cond. No.          </th> <td>1.76e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.76e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                   loan   R-squared (uncentered):                   0.151\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.150\n",
       "Method:                 Least Squares   F-statistic:                              90.24\n",
       "Date:                Tue, 16 Feb 2021   Prob (F-statistic):                   2.60e-290\n",
       "Time:                        21:48:09   Log-Likelihood:                         -3218.8\n",
       "No. Observations:                8622   AIC:                                      6472.\n",
       "Df Residuals:                    8605   BIC:                                      6592.\n",
       "Df Model:                          17                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "village        -0.0005      0.000     -2.407      0.016      -0.001   -8.43e-05\n",
       "rooms          -0.0063      0.003     -1.838      0.066      -0.013       0.000\n",
       "beds           -0.0105      0.003     -3.432      0.001      -0.016      -0.005\n",
       "electricity     0.0572      0.015      3.946      0.000       0.029       0.086\n",
       "leader          0.0583      0.012      4.870      0.000       0.035       0.082\n",
       "connections     0.0007      0.000      2.809      0.005       0.000       0.001\n",
       "christian       0.0939      0.134      0.701      0.483      -0.169       0.356\n",
       "hindu          -0.0437      0.016     -2.809      0.005      -0.074      -0.013\n",
       "rcc             0.0482      0.020      2.415      0.016       0.009       0.087\n",
       "sheet           0.0794      0.017      4.548      0.000       0.045       0.114\n",
       "stone           0.0778      0.017      4.599      0.000       0.045       0.111\n",
       "thatch          0.1193      0.030      4.029      0.000       0.061       0.177\n",
       "tile            0.0975      0.017      5.714      0.000       0.064       0.131\n",
       "LEASED          0.1187      0.092      1.285      0.199      -0.062       0.300\n",
       "OWNED           0.0759      0.018      4.298      0.000       0.041       0.110\n",
       "RENTED          0.0793      0.023      3.401      0.001       0.034       0.125\n",
       "SHARE_OWNED     0.0967      0.043      2.233      0.026       0.012       0.182\n",
       "==============================================================================\n",
       "Omnibus:                     2900.913   Durbin-Watson:                   1.685\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6988.377\n",
       "Skew:                           1.969   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.986   Cond. No.                     1.76e+03\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.76e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OLS\n",
    "X = table.drop('loan', axis=1)\n",
    "y = table['loan']\n",
    "OLS = linear_model.OLS(y, X).fit()\n",
    "OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>loan</td>       <th>  R-squared (uncentered):</th>      <td>   0.093</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.092</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   879.5</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 16 Feb 2021</td> <th>  Prob (F-statistic):</th>          <td>3.96e-184</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>21:48:15</td>     <th>  Log-Likelihood:    </th>          <td> -3507.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8622</td>      <th>  AIC:               </th>          <td>   7016.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8621</td>      <th>  BIC:               </th>          <td>   7024.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "       <td></td>          <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>connections</th> <td>    0.0048</td> <td>    0.000</td> <td>   29.656</td> <td> 0.000</td> <td>    0.004</td> <td>    0.005</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2718.182</td> <th>  Durbin-Watson:     </th> <td>   1.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>6233.614</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.864</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 4.857</td>  <th>  Cond. No.          </th> <td>    1.00</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                   loan   R-squared (uncentered):                   0.093\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.092\n",
       "Method:                 Least Squares   F-statistic:                              879.5\n",
       "Date:                Tue, 16 Feb 2021   Prob (F-statistic):                   3.96e-184\n",
       "Time:                        21:48:15   Log-Likelihood:                         -3507.2\n",
       "No. Observations:                8622   AIC:                                      7016.\n",
       "Df Residuals:                    8621   BIC:                                      7024.\n",
       "Df Model:                           1                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "===============================================================================\n",
       "                  coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------\n",
       "connections     0.0048      0.000     29.656      0.000       0.004       0.005\n",
       "==============================================================================\n",
       "Omnibus:                     2718.182   Durbin-Watson:                   1.612\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             6233.614\n",
       "Skew:                           1.864   Prob(JB):                         0.00\n",
       "Kurtosis:                       4.857   Cond. No.                         1.00\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Regressing y on d\n",
    "OLS2 = linear_model.OLS(y, conn).fit()\n",
    "OLS2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting d hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating d hat\n",
    "\n",
    "# Transforming degrees\n",
    "conn = table['connections']\n",
    "\n",
    "v = table['village']\n",
    "v_sq = v**2\n",
    "v_sq3 = v**3\n",
    "v2 = v + v_sq\n",
    "v3 = v2 + v_sq3\n",
    "rm = table['rooms']\n",
    "rm_sq = rm**2\n",
    "rm2 = rm + rm_sq\n",
    "b = table['beds']\n",
    "b_sq = b**2\n",
    "b2 = b + b_sq\n",
    "e = table['electricity']\n",
    "e_sq = e**2\n",
    "e2 = e + e_sq\n",
    "l = table['leader']\n",
    "l_sq = l**2\n",
    "l2 = l + l_sq\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>village^1</th>\n",
       "      <th>rooms^1</th>\n",
       "      <th>beds^1</th>\n",
       "      <th>electricity^1</th>\n",
       "      <th>leader^1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   village^1  rooms^1  beds^1  electricity^1  leader^1\n",
       "0        1.0      3.0     4.0            0.0       0.0\n",
       "1        1.0      1.0     1.0            1.0       1.0\n",
       "2        1.0      3.0     4.0            1.0       1.0\n",
       "3        1.0      2.0     6.0            1.0       0.0\n",
       "4        1.0      3.0     4.0            1.0       0.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create interaction terms up to the third degree\n",
    "mini_table = pd.concat([v,rm,b,e,l], axis = 1)\n",
    "\n",
    "poly1 = preprocessing.PolynomialFeatures(1, interaction_only=False, include_bias=False)\n",
    "table_array1 = poly1.fit_transform(mini_table)\n",
    "target_feature_names1 = ['_x_'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(mini_table.columns,p) for p in poly1.powers_]]\n",
    "Xd1 = pd.DataFrame(table_array1, columns = target_feature_names1)\n",
    "Xd1.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>village^1</th>\n",
       "      <th>rooms^1</th>\n",
       "      <th>beds^1</th>\n",
       "      <th>electricity^1</th>\n",
       "      <th>leader^1</th>\n",
       "      <th>village^2</th>\n",
       "      <th>village^1_x_rooms^1</th>\n",
       "      <th>village^1_x_beds^1</th>\n",
       "      <th>village^1_x_electricity^1</th>\n",
       "      <th>village^1_x_leader^1</th>\n",
       "      <th>rooms^2</th>\n",
       "      <th>rooms^1_x_beds^1</th>\n",
       "      <th>rooms^1_x_electricity^1</th>\n",
       "      <th>rooms^1_x_leader^1</th>\n",
       "      <th>beds^2</th>\n",
       "      <th>beds^1_x_electricity^1</th>\n",
       "      <th>beds^1_x_leader^1</th>\n",
       "      <th>electricity^2</th>\n",
       "      <th>electricity^1_x_leader^1</th>\n",
       "      <th>leader^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   village^1  rooms^1  beds^1  electricity^1  leader^1  village^2  \\\n",
       "0        1.0      3.0     4.0            0.0       0.0        1.0   \n",
       "1        1.0      1.0     1.0            1.0       1.0        1.0   \n",
       "2        1.0      3.0     4.0            1.0       1.0        1.0   \n",
       "3        1.0      2.0     6.0            1.0       0.0        1.0   \n",
       "4        1.0      3.0     4.0            1.0       0.0        1.0   \n",
       "\n",
       "   village^1_x_rooms^1  village^1_x_beds^1  village^1_x_electricity^1  \\\n",
       "0                  3.0                 4.0                        0.0   \n",
       "1                  1.0                 1.0                        1.0   \n",
       "2                  3.0                 4.0                        1.0   \n",
       "3                  2.0                 6.0                        1.0   \n",
       "4                  3.0                 4.0                        1.0   \n",
       "\n",
       "   village^1_x_leader^1  rooms^2  rooms^1_x_beds^1  rooms^1_x_electricity^1  \\\n",
       "0                   0.0      9.0              12.0                      0.0   \n",
       "1                   1.0      1.0               1.0                      1.0   \n",
       "2                   1.0      9.0              12.0                      3.0   \n",
       "3                   0.0      4.0              12.0                      2.0   \n",
       "4                   0.0      9.0              12.0                      3.0   \n",
       "\n",
       "   rooms^1_x_leader^1  beds^2  beds^1_x_electricity^1  beds^1_x_leader^1  \\\n",
       "0                 0.0    16.0                     0.0                0.0   \n",
       "1                 1.0     1.0                     1.0                1.0   \n",
       "2                 3.0    16.0                     4.0                4.0   \n",
       "3                 0.0    36.0                     6.0                0.0   \n",
       "4                 0.0    16.0                     4.0                0.0   \n",
       "\n",
       "   electricity^2  electricity^1_x_leader^1  leader^2  \n",
       "0            0.0                       0.0       0.0  \n",
       "1            1.0                       1.0       1.0  \n",
       "2            1.0                       1.0       1.0  \n",
       "3            1.0                       0.0       0.0  \n",
       "4            1.0                       0.0       0.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly2 = preprocessing.PolynomialFeatures(2, interaction_only=False, include_bias=False)\n",
    "table_array2 = poly2.fit_transform(mini_table)\n",
    "target_feature_names2 = ['_x_'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(mini_table.columns,p) for p in poly2.powers_]]\n",
    "Xd2 = pd.DataFrame(table_array2, columns = target_feature_names2)\n",
    "Xd2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>village^1</th>\n",
       "      <th>rooms^1</th>\n",
       "      <th>beds^1</th>\n",
       "      <th>electricity^1</th>\n",
       "      <th>leader^1</th>\n",
       "      <th>village^2</th>\n",
       "      <th>village^1_x_rooms^1</th>\n",
       "      <th>village^1_x_beds^1</th>\n",
       "      <th>village^1_x_electricity^1</th>\n",
       "      <th>village^1_x_leader^1</th>\n",
       "      <th>...</th>\n",
       "      <th>beds^3</th>\n",
       "      <th>beds^2_x_electricity^1</th>\n",
       "      <th>beds^2_x_leader^1</th>\n",
       "      <th>beds^1_x_electricity^2</th>\n",
       "      <th>beds^1_x_electricity^1_x_leader^1</th>\n",
       "      <th>beds^1_x_leader^2</th>\n",
       "      <th>electricity^3</th>\n",
       "      <th>electricity^2_x_leader^1</th>\n",
       "      <th>electricity^1_x_leader^2</th>\n",
       "      <th>leader^3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>216.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   village^1  rooms^1  beds^1  electricity^1  leader^1  village^2  \\\n",
       "0        1.0      3.0     4.0            0.0       0.0        1.0   \n",
       "1        1.0      1.0     1.0            1.0       1.0        1.0   \n",
       "2        1.0      3.0     4.0            1.0       1.0        1.0   \n",
       "3        1.0      2.0     6.0            1.0       0.0        1.0   \n",
       "4        1.0      3.0     4.0            1.0       0.0        1.0   \n",
       "\n",
       "   village^1_x_rooms^1  village^1_x_beds^1  village^1_x_electricity^1  \\\n",
       "0                  3.0                 4.0                        0.0   \n",
       "1                  1.0                 1.0                        1.0   \n",
       "2                  3.0                 4.0                        1.0   \n",
       "3                  2.0                 6.0                        1.0   \n",
       "4                  3.0                 4.0                        1.0   \n",
       "\n",
       "   village^1_x_leader^1  ...  beds^3  beds^2_x_electricity^1  \\\n",
       "0                   0.0  ...    64.0                     0.0   \n",
       "1                   1.0  ...     1.0                     1.0   \n",
       "2                   1.0  ...    64.0                    16.0   \n",
       "3                   0.0  ...   216.0                    36.0   \n",
       "4                   0.0  ...    64.0                    16.0   \n",
       "\n",
       "   beds^2_x_leader^1  beds^1_x_electricity^2  \\\n",
       "0                0.0                     0.0   \n",
       "1                1.0                     1.0   \n",
       "2               16.0                     4.0   \n",
       "3                0.0                     6.0   \n",
       "4                0.0                     4.0   \n",
       "\n",
       "   beds^1_x_electricity^1_x_leader^1  beds^1_x_leader^2  electricity^3  \\\n",
       "0                                0.0                0.0            0.0   \n",
       "1                                1.0                1.0            1.0   \n",
       "2                                4.0                4.0            1.0   \n",
       "3                                0.0                0.0            1.0   \n",
       "4                                0.0                0.0            1.0   \n",
       "\n",
       "   electricity^2_x_leader^1  electricity^1_x_leader^2  leader^3  \n",
       "0                       0.0                       0.0       0.0  \n",
       "1                       1.0                       1.0       1.0  \n",
       "2                       1.0                       1.0       1.0  \n",
       "3                       0.0                       0.0       0.0  \n",
       "4                       0.0                       0.0       0.0  \n",
       "\n",
       "[5 rows x 55 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly3 = preprocessing.PolynomialFeatures(3, interaction_only=False, include_bias=False)\n",
    "table_array3 = poly3.fit_transform(mini_table)\n",
    "target_feature_names3 = ['_x_'.join(['{}^{}'.format(pair[0],pair[1]) for pair in tuple if pair[1]!=0]) for tuple in [zip(mini_table.columns,p) for p in poly3.powers_]]\n",
    "Xd3 = pd.DataFrame(table_array3, columns = target_feature_names3)\n",
    "Xd3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_mod = LassoLarsCV(cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.744666535108633\n",
      "0.06810404905650358\n"
     ]
    }
   ],
   "source": [
    "# Predicting d hat using different degrees of interction\n",
    "ls_fit = ls_mod.fit(Xd1,conn)\n",
    "pred1 = ls_fit.predict(Xd1)\n",
    "print(np.sqrt(mean_squared_error(conn,pred1)))\n",
    "print(r2_score(conn,pred1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.685387628475876\n",
      "0.07558210587868486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 10 iterations, i.e. alpha=2.789e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.288e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.657e-04, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=2.166e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.191e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 21 iterations, i.e. alpha=1.004e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.692e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=4.692e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 23 iterations, i.e. alpha=1.635e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.933e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.986e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=1.986e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:597: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 14 iterations, alpha=1.662e-03, previous alpha=1.641e-03, with an active set of 11 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=1.838e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.216e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=9.216e-04, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=5.687e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=3.372e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=8.205e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=7.757e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 17 iterations, i.e. alpha=5.568e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=4.888e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.518e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=7.518e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=1.134e-05, with an active set of 17 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.659e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=2.659e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=1.329e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=4.112e-04, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.682e-04, with an active set of 15 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=1.525e-04, with an active set of 16 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:597: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=1.787e-04, previous alpha=7.416e-05, with an active set of 16 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n"
     ]
    }
   ],
   "source": [
    "ls_fit2 = ls_mod.fit(Xd2,conn)\n",
    "pred2 = ls_fit2.predict(Xd2)\n",
    "print(np.sqrt(mean_squared_error(conn,pred2)))\n",
    "print(r2_score(conn,pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14.735469654566929\n",
      "0.06926621339741557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.637e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.637e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.184e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.184e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.184e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=8.184e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=7.252e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 4.470e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.092e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 4.712e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.092e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 19 iterations, i.e. alpha=4.092e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:597: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 20 iterations, alpha=4.087e-03, previous alpha=3.995e-03, with an active set of 13 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.154e-03, with an active set of 7 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.525e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.525e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.980e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.525e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 20 iterations, i.e. alpha=2.118e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:597: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 22 iterations, alpha=1.916e-03, previous alpha=1.869e-03, with an active set of 13 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.263e-02, with an active set of 4 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.974e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.974e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.974e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 13 iterations, i.e. alpha=3.616e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.000e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.000e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=3.000e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 4.215e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=2.953e-03, with an active set of 13 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.839e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.833e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 18 iterations, i.e. alpha=1.758e-03, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:597: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.877e-03, previous alpha=1.659e-03, with an active set of 14 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.680e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=1.680e-02, with an active set of 5 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.123e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 5.576e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=1.123e-02, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.399e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=8.399e-03, with an active set of 8 regressors, and the smallest cholesky pivot element being 2.581e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 24 iterations, i.e. alpha=5.596e-03, with an active set of 12 regressors, and the smallest cholesky pivot element being 5.674e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.220e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.179e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 4.942e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 34 iterations, i.e. alpha=4.179e-03, with an active set of 18 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.641e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 2.788e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.320e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 42 iterations, i.e. alpha=2.203e-03, with an active set of 22 regressors, and the smallest cholesky pivot element being 5.960e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:597: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 43 iterations, alpha=2.632e-03, previous alpha=2.199e-03, with an active set of 22 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=8.201e-03, with an active set of 5 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.545e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=3.545e-03, with an active set of 9 regressors, and the smallest cholesky pivot element being 1.054e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.357e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.357e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=3.357e-03, with an active set of 11 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:597: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=2.168e-03, previous alpha=2.146e-03, with an active set of 12 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 2 iterations, i.e. alpha=2.387e-02, with an active set of 2 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.867e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.107e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.867e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.220e-16. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=7.867e-03, with an active set of 10 regressors, and the smallest cholesky pivot element being 2.356e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:597: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=7.856e-03, previous alpha=7.778e-03, with an active set of 10 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n"
     ]
    }
   ],
   "source": [
    "ls_fit3 = ls_mod.fit(Xd3,conn)\n",
    "pred3 = ls_fit3.predict(Xd3)\n",
    "print(np.sqrt(mean_squared_error(conn,pred3)))\n",
    "print(r2_score(conn,pred3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Variables  Coefficient Estimate\n",
      "0                   village^1              0.000000\n",
      "1                     rooms^1              0.000000\n",
      "2                      beds^1             -1.346689\n",
      "3               electricity^1              0.000000\n",
      "4                    leader^1              0.000000\n",
      "5                   village^2              0.000000\n",
      "6         village^1_x_rooms^1              0.000000\n",
      "7          village^1_x_beds^1              0.012229\n",
      "8   village^1_x_electricity^1              0.000000\n",
      "9        village^1_x_leader^1              0.000000\n",
      "10                    rooms^2              0.000000\n",
      "11           rooms^1_x_beds^1              0.000000\n",
      "12    rooms^1_x_electricity^1              0.719084\n",
      "13         rooms^1_x_leader^1              1.350495\n",
      "14                     beds^2              0.000000\n",
      "15     beds^1_x_electricity^1              0.560074\n",
      "16          beds^1_x_leader^1              0.504306\n",
      "17              electricity^2              0.000000\n",
      "18   electricity^1_x_leader^1              0.000000\n",
      "19                   leader^2              0.000000\n"
     ]
    }
   ],
   "source": [
    "# interaction to the second degree has the best performance so we will use that to create our d hat\n",
    "lasso_coeff = pd.DataFrame()\n",
    "lasso_coeff[\"Variables\"] = Xd2.columns\n",
    "lasso_coeff[\"Coefficient Estimate\"] = pd.Series(ls_mod.coef_)\n",
    "print(lasso_coeff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Two step lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    alpha       mse\n",
      "0     1.0  0.127429\n",
      "1     2.0  0.127738\n",
      "2     3.0  0.134072\n",
      "3     4.0  0.134074\n",
      "4     5.0  0.134075\n",
      "5     6.0  0.134076\n",
      "6     7.0  0.134079\n",
      "7     8.0  0.134080\n",
      "8     9.0  0.134082\n",
      "9    10.0  0.134086\n",
      "10   11.0  0.134086\n",
      "11   12.0  0.134090\n",
      "12   13.0  0.134093\n",
      "13   14.0  0.134125\n",
      "14   15.0  0.134091\n",
      "15   16.0  0.134102\n",
      "16   17.0  0.134133\n",
      "17   18.0  0.134131\n",
      "18   19.0  0.134135\n",
      "19   20.0  0.134119\n",
      "20   21.0  0.134109\n",
      "21   22.0  0.134140\n",
      "22   23.0  0.134139\n",
      "23   24.0  0.134142\n",
      "24   25.0  0.134139\n",
      "25   26.0  0.134159\n",
      "26   27.0  0.134169\n",
      "27   28.0  0.134153\n",
      "28   29.0  0.134127\n",
      "29   30.0  0.134139\n",
      "30   31.0  0.134154\n",
      "31   32.0  0.134155\n",
      "32   33.0  0.134171\n",
      "33   34.0  0.134178\n",
      "34   35.0  0.134228\n",
      "35   36.0  0.134260\n",
      "36   37.0  0.134293\n",
      "37   38.0  0.134274\n",
      "38   39.0  0.134347\n",
      "39   40.0  0.134413\n",
      "40   41.0  0.134314\n",
      "41   42.0  0.134327\n",
      "42   43.0  0.134297\n",
      "43   44.0  0.134329\n",
      "44   45.0  0.134492\n",
      "45   46.0  0.134517\n",
      "46   47.0  0.134561\n",
      "47   48.0  0.134463\n",
      "48   49.0  0.134400\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import minimize\n",
    "\n",
    "dhat = pd.DataFrame(pred2) # using pred2 as dhat\n",
    "d = conn\n",
    "A = pd.concat([d, dhat, Xd2], axis = 1)\n",
    "alphas = list(range(1,50,1)) # change value of alpha --> sequence of values\n",
    "\n",
    "y = data[\"loan\"] # response variable\n",
    "x0 = np.zeros(A.shape[1])\n",
    "\n",
    "weights = np.ones(A.shape[1]) # starting with every column having a weight of 1\n",
    "weights[[0,1]] = 0.0 # assigning zero weight to d and d_hat so we don't penalize them\n",
    "\n",
    "choice = pd.DataFrame(columns=['alpha', 'mse'])\n",
    "\n",
    "for alpha in alphas:\n",
    "    def lasso(x):  # following sklearn's definition from user-guide!\n",
    "        return (1. / (2*A.shape[0])) * np.square(np.linalg.norm(A.dot(x) - y, 2)) + alpha * np.linalg.norm(weights*x, 1)\n",
    "\n",
    "    res = minimize(lasso, x0, method='L-BFGS-B', options={'disp': False})\n",
    "    m = res.x*A\n",
    "    y_pred = m.sum(axis = 1)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    choice.loc[len(choice.index)] = [alpha, mse]\n",
    "\n",
    "print(choice)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   alpha       mse\n",
      "0    1.0  0.127429\n"
     ]
    }
   ],
   "source": [
    "print(choice[choice.mse == choice.mse.min()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Variables  Coefficient Estimate\n",
      "0                 connections          3.101955e-03\n",
      "1                           0          3.119680e-03\n",
      "2                   village^1          7.337317e-11\n",
      "3                     rooms^1         -1.987730e-06\n",
      "4                      beds^1          4.675798e-06\n",
      "5               electricity^1          4.311257e-08\n",
      "6                    leader^1          1.325974e-06\n",
      "7                   village^2          4.699840e-06\n",
      "8         village^1_x_rooms^1         -4.137028e-06\n",
      "9          village^1_x_beds^1         -7.032734e-05\n",
      "10  village^1_x_electricity^1          5.240260e-07\n",
      "11       village^1_x_leader^1         -1.044145e-06\n",
      "12                    rooms^2          6.532678e-08\n",
      "13           rooms^1_x_beds^1         -2.389802e-07\n",
      "14    rooms^1_x_electricity^1          1.558592e-06\n",
      "15         rooms^1_x_leader^1         -1.110958e-06\n",
      "16                     beds^2          1.935475e-06\n",
      "17     beds^1_x_electricity^1          6.279434e-06\n",
      "18          beds^1_x_leader^1          1.381250e-06\n",
      "19              electricity^2          4.311257e-08\n",
      "20   electricity^1_x_leader^1          5.540680e-07\n",
      "21                   leader^2          1.325974e-06\n"
     ]
    }
   ],
   "source": [
    "alpha = choice[choice.mse == choice.mse.min()].alpha\n",
    "dhat = pd.DataFrame(pred2) # using pred3 as dhat\n",
    "d = conn\n",
    "A = pd.concat([d, dhat, Xd2], axis = 1)\n",
    "\n",
    "y = data[\"loan\"] # response variable\n",
    "x0 = np.zeros(A.shape[1])\n",
    "\n",
    "weights = np.ones(A.shape[1]) # starting with every column having a weight of 1\n",
    "weights[[0,1]] = 0.0 # assigning zero weight to d and d_hat so we don't penalize them\n",
    "\n",
    "def lasso(x):  # following sklearn's definition from user-guide!\n",
    "    return (1. / (2*A.shape[0])) * np.square(np.linalg.norm(A.dot(x) - y, 2)) + alpha * np.linalg.norm(weights*x, 1)\n",
    "\n",
    "res = minimize(lasso, x0, method='L-BFGS-B', options={'disp': False})\n",
    "m = res.x*A\n",
    "y_pred = m.sum(axis = 1)\n",
    "   \n",
    "lasso_2stage_coef = pd.DataFrame()\n",
    "lasso_2stage_coef[\"Variables\"] = A.columns\n",
    "lasso_2stage_coef[\"Coefficient Estimate\"] = pd.Series(res.x)\n",
    "print(lasso_2stage_coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12742910103971283\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y, y_pred)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>connections</th>\n",
       "      <th>0</th>\n",
       "      <th>rooms^1</th>\n",
       "      <th>beds^1</th>\n",
       "      <th>village^2</th>\n",
       "      <th>leader^1</th>\n",
       "      <th>village^2</th>\n",
       "      <th>village^1_x_rooms^1</th>\n",
       "      <th>village^1_x_beds^1</th>\n",
       "      <th>village^1_x_leader^1</th>\n",
       "      <th>rooms^1_x_electricity^1</th>\n",
       "      <th>rooms^1_x_leader^1</th>\n",
       "      <th>beds^2</th>\n",
       "      <th>beds^1_x_electricity^1</th>\n",
       "      <th>beds^1_x_leader^1</th>\n",
       "      <th>leader^2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>13.062720</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>17.903812</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>23.800725</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>15.596844</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16</td>\n",
       "      <td>16.313300</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   connections          0  rooms^1  beds^1  village^2  leader^1  village^2  \\\n",
       "0           10  13.062720      3.0     4.0        1.0       0.0        1.0   \n",
       "1           14  17.903812      1.0     1.0        1.0       1.0        1.0   \n",
       "2            4  23.800725      3.0     4.0        1.0       1.0        1.0   \n",
       "3            8  15.596844      2.0     6.0        1.0       0.0        1.0   \n",
       "4           16  16.313300      3.0     4.0        1.0       0.0        1.0   \n",
       "\n",
       "   village^1_x_rooms^1  village^1_x_beds^1  village^1_x_leader^1  \\\n",
       "0                  3.0                 4.0                   0.0   \n",
       "1                  1.0                 1.0                   1.0   \n",
       "2                  3.0                 4.0                   1.0   \n",
       "3                  2.0                 6.0                   0.0   \n",
       "4                  3.0                 4.0                   0.0   \n",
       "\n",
       "   rooms^1_x_electricity^1  rooms^1_x_leader^1  beds^2  \\\n",
       "0                      0.0                 0.0    16.0   \n",
       "1                      1.0                 1.0     1.0   \n",
       "2                      3.0                 3.0    16.0   \n",
       "3                      2.0                 0.0    36.0   \n",
       "4                      3.0                 0.0    16.0   \n",
       "\n",
       "   beds^1_x_electricity^1  beds^1_x_leader^1  leader^2  \n",
       "0                     0.0                0.0       0.0  \n",
       "1                     1.0                1.0       1.0  \n",
       "2                     4.0                4.0       1.0  \n",
       "3                     6.0                0.0       0.0  \n",
       "4                     4.0                0.0       0.0  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# threshold for selecting variables = e-07\n",
    "lasso_var_retained = pd.concat([d, dhat, Xd2[\"rooms^1\"], Xd2[\"beds^1\"], Xd2[\"village^2\"], Xd2[\"leader^1\"], Xd2[\"village^2\"], \n",
    "                                Xd2[\"village^1_x_rooms^1\"], Xd2[\"village^1_x_beds^1\"], Xd2[\"village^1_x_leader^1\"], \n",
    "                               Xd2[\"rooms^1_x_electricity^1\"], Xd2[\"rooms^1_x_leader^1\"], Xd2[\"beds^2\"], Xd2[\"beds^1_x_electricity^1\"], \n",
    "                               Xd2[\"beds^1_x_leader^1\"], Xd3[\"leader^2\"]], axis = 1)\n",
    "lasso_var_retained.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>          <td>loan</td>       <th>  R-squared (uncentered):</th>      <td>   0.154</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared (uncentered):</th> <td>   0.153</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th>          <td>   112.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Tue, 16 Feb 2021</td> <th>  Prob (F-statistic):</th>          <td>1.11e-299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>22:34:34</td>     <th>  Log-Likelihood:    </th>          <td> -3204.0</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  8622</td>      <th>  AIC:               </th>          <td>   6436.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  8608</td>      <th>  BIC:               </th>          <td>   6535.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    14</td>      <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>              <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>                <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>connections</th>             <td>    0.0006</td> <td>    0.000</td> <td>    2.349</td> <td> 0.019</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>                       <td>    0.0117</td> <td>    0.001</td> <td>   13.000</td> <td> 0.000</td> <td>    0.010</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rooms^1</th>                 <td>   -0.0095</td> <td>    0.012</td> <td>   -0.817</td> <td> 0.414</td> <td>   -0.032</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>beds^1</th>                  <td>    0.0247</td> <td>    0.022</td> <td>    1.149</td> <td> 0.251</td> <td>   -0.017</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>village^2</th>               <td>-3.419e-06</td> <td> 2.29e-06</td> <td>   -1.491</td> <td> 0.136</td> <td>-7.92e-06</td> <td> 1.08e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leader^1</th>                <td>    0.0440</td> <td>    0.016</td> <td>    2.728</td> <td> 0.006</td> <td>    0.012</td> <td>    0.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>village^2</th>               <td>-3.419e-06</td> <td> 2.29e-06</td> <td>   -1.491</td> <td> 0.136</td> <td>-7.92e-06</td> <td> 1.08e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>village^1_x_rooms^1</th>     <td>   -0.0003</td> <td>    0.000</td> <td>   -1.996</td> <td> 0.046</td> <td>   -0.001</td> <td>-5.26e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>village^1_x_beds^1</th>      <td>   -0.0002</td> <td>    0.000</td> <td>   -1.524</td> <td> 0.128</td> <td>   -0.001</td> <td>  6.3e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>village^1_x_leader^1</th>    <td>    0.0004</td> <td>    0.001</td> <td>    0.759</td> <td> 0.448</td> <td>   -0.001</td> <td>    0.002</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rooms^1_x_electricity^1</th> <td>    0.0023</td> <td>    0.009</td> <td>    0.247</td> <td> 0.805</td> <td>   -0.016</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>rooms^1_x_leader^1</th>      <td>   -0.0399</td> <td>    0.009</td> <td>   -4.597</td> <td> 0.000</td> <td>   -0.057</td> <td>   -0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>beds^2</th>                  <td>    0.0003</td> <td>    0.000</td> <td>    1.898</td> <td> 0.058</td> <td> -1.1e-05</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>beds^1_x_electricity^1</th>  <td>   -0.0425</td> <td>    0.021</td> <td>   -1.989</td> <td> 0.047</td> <td>   -0.084</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>beds^1_x_leader^1</th>       <td>   -0.0044</td> <td>    0.009</td> <td>   -0.492</td> <td> 0.623</td> <td>   -0.022</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>leader^2</th>                <td>    0.0440</td> <td>    0.016</td> <td>    2.728</td> <td> 0.006</td> <td>    0.012</td> <td>    0.076</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>2921.976</td> <th>  Durbin-Watson:     </th> <td>   1.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th>  <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>7079.993</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>           <td> 1.981</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>       <td> 5.003</td>  <th>  Cond. No.          </th> <td>1.33e+20</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 7.34e-30. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                                 OLS Regression Results                                \n",
       "=======================================================================================\n",
       "Dep. Variable:                   loan   R-squared (uncentered):                   0.154\n",
       "Model:                            OLS   Adj. R-squared (uncentered):              0.153\n",
       "Method:                 Least Squares   F-statistic:                              112.1\n",
       "Date:                Tue, 16 Feb 2021   Prob (F-statistic):                   1.11e-299\n",
       "Time:                        22:34:34   Log-Likelihood:                         -3204.0\n",
       "No. Observations:                8622   AIC:                                      6436.\n",
       "Df Residuals:                    8608   BIC:                                      6535.\n",
       "Df Model:                          14                                                  \n",
       "Covariance Type:            nonrobust                                                  \n",
       "===========================================================================================\n",
       "                              coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-------------------------------------------------------------------------------------------\n",
       "connections                 0.0006      0.000      2.349      0.019       0.000       0.001\n",
       "0                           0.0117      0.001     13.000      0.000       0.010       0.013\n",
       "rooms^1                    -0.0095      0.012     -0.817      0.414      -0.032       0.013\n",
       "beds^1                      0.0247      0.022      1.149      0.251      -0.017       0.067\n",
       "village^2               -3.419e-06   2.29e-06     -1.491      0.136   -7.92e-06    1.08e-06\n",
       "leader^1                    0.0440      0.016      2.728      0.006       0.012       0.076\n",
       "village^2               -3.419e-06   2.29e-06     -1.491      0.136   -7.92e-06    1.08e-06\n",
       "village^1_x_rooms^1        -0.0003      0.000     -1.996      0.046      -0.001   -5.26e-06\n",
       "village^1_x_beds^1         -0.0002      0.000     -1.524      0.128      -0.001     6.3e-05\n",
       "village^1_x_leader^1        0.0004      0.001      0.759      0.448      -0.001       0.002\n",
       "rooms^1_x_electricity^1     0.0023      0.009      0.247      0.805      -0.016       0.021\n",
       "rooms^1_x_leader^1         -0.0399      0.009     -4.597      0.000      -0.057      -0.023\n",
       "beds^2                      0.0003      0.000      1.898      0.058    -1.1e-05       0.001\n",
       "beds^1_x_electricity^1     -0.0425      0.021     -1.989      0.047      -0.084      -0.001\n",
       "beds^1_x_leader^1          -0.0044      0.009     -0.492      0.623      -0.022       0.013\n",
       "leader^2                    0.0440      0.016      2.728      0.006       0.012       0.076\n",
       "==============================================================================\n",
       "Omnibus:                     2921.976   Durbin-Watson:                   1.682\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             7079.993\n",
       "Skew:                           1.981   Prob(JB):                         0.00\n",
       "Kurtosis:                       5.003   Cond. No.                     1.33e+20\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 7.34e-30. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Linear Reg with variables selected by lasso\n",
    "x = lasso_var_retained\n",
    "OLS_2 = linear_model.OLS(y, x).fit()\n",
    "OLS_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_pred = OLS_2.predict()\n",
    "plt.hist(y_pred)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.12311316747703073"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate MSE\n",
    "mean_squared_error(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    7367\n",
       "1    1255\n",
       "Name: loan, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# actual balance of loan\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8544421247970309 0.14555787520296914\n"
     ]
    }
   ],
   "source": [
    "# threshold for 0/1 loan\n",
    "percent_zero = y.value_counts()[0]/y.count()\n",
    "percent_one = y.value_counts()[1]/y.count()\n",
    "print(percent_zero, percent_one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAEICAYAAABhxi57AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAUQUlEQVR4nO3df5RcZX3H8fc32Q0JCT8TDJJEF9xEGyUqjYoVbWzDMQQtVNvTWjBLlSrHnphCQaBuBU4XUY8FIf4qRSURxR+naKkEziFaD/XwQxMlICEmKwRIICEsv0wIIZs8/WPuxslmNjubzMwzYd+vc+Zw79zn3ud779z5zJ3nzoZIKSFJarwRuQuQpOHKAJakTAxgScrEAJakTAxgScrEAJakTAzgYSYiro+IrmL6nRHx2wb1myKivRF9DTeNfB1VWwZwE4qItRGxNSI2R8TGiPhmRIyrdT8ppf9LKb22inrOioif17r/su3/LCLOrtf2q+i/rfiA2Fw81kbERbnqGar+r2NR/+ycNak6BnDzel9KaRxwAvAWoLN/g4hoaXhVL2+HF8f8g8CnI2JO/wYec9WSAdzkUkrrgVuBN8Cur/L/GBFrgDXFc++NiHsj4tmIuDMiZvStHxFvjohfRcTvI+J7wOiyZbMiYl3Z/JSIuCkiNkVET0R8KSL+CPga8Pbi6vDZou1BEfGFiHi0uEr/WkSMKdvWBRHxREQ8HhEf3pd9j4gREdEZEY9ExJMRsTgiDitb/oOI2BARz0XEHRHx+rJl10fElyPilmLf74mI11TTb0rpLuAB4A19xygiLoyIDcA3i33/YrFvjxfTB5Uf04j4l4h4qrgaPaOsrgGPW9m6/1zs7xMR8fdl686NiJXF/qyPiPPL1yumvwW8Cvif4vX6ZHEM5vc7tvdFxOlDflFUUwZwk4uIKcBc4NdlT58OvA2YHhEnAN8APgaMB/4DuLl4o48CfgR8CzgS+AHwgQH6GQn8GHgEaAMmAd9NKT0InAPclVIal1I6vFjlc8A04E1Ae9H+08W25gDnAycDU4F9/Tp8VvF4N3AcMA74UtnyW4vtvwL4FfDtfut/ELgMOALoBi4frMMoeQfwev5wzI+mdPxeDXwU+BRwIqV9fyPwVnb/hnI0MIHSMekAro2IviGCAY9b2bqHFc9/BPhyRBxRLPs68LGU0iGUPpB/2r/+lNKHgEcpvkGllD4PLALOLNvHNxbbXzLY8VCdpZR8NNkDWAtsBp6lFIhfAcYUyxLwZ2Vtvwr8W7/1fwv8KfAu4HEgypbdCXQV07OAdcX024FNQEuFes4Cfl42H8AW4DVlz70deLiY/gbw2bJl04q62wfY358BZ1d4/ifAx8vmXwtsH6DGw4s+DivmrweuK1s+F1g1QP9txbrPAs8ADwKfKDtGLwGjy9r/DphbNv8eYG1Z+15gbNny7wP/WsVxmwVsLd8/4EngxGL6UUoftIf2q3/X61h2/swumz8IeBqYWsx/AfhK7vPcR8LxrOZ1ekpp6QDLHiubfjXQ0e8r5ijgGEqhsj4V77rCIwNscwrwSEqpt4rajgIOBpZHRN9zAYwspo8BllfR52CO6bfuI0ALMLEYDrgc+Ouinp1FmwnAc8X0hrJ1X6B0Bb03EwbY/00ppRcHqeuYsvlnUkpbKiwf7LgB9PSrobzuD1C60v5sRNwHXJRKwyV7lVLaFhHfB86MiMsofTP4q8HWU/05BHFgKg/Ux4DLU0qHlz0OTindCDwBTIqydzul8cFKHgNeNcBNpv7/ZN5TlK7UXl/W52GpdAOLot8pVfQ5mMcpfcCUb6cX2Aj8HXAapeGNwyhdxUIp0Gqt//5XquvxsvkjImJsheWDHbe9F5HSL1NKp1EacvkRpSvrauqF0jDEGcCfAy9UE9yqPwP4wPefwDkR8bZi/HJsRJwaEYcAd1EKrE9EREtEvJ/SeGUlv6AUnJ8ttjG6GAuFUuBNLsaUSSntLPq9KiJeARARkyLiPUX77wNnRcT0iDgYuKSK/Wgp+ux7tAI3AudGxLFR+hneZ4DvFVeIhwDbgB5KV5WfqfqI7b8bgc6IOCoiJlAaw72hX5vLImJURLwTeC/wgyqO24CKbZ0REYellLYDzwM7Bmi+kdKY+S5F4O4E/p3SPQE1AQP4AJdSWgb8A6WbU89Qutl0VrHsJeD9xfwzwN8ANw2wnR3A+yjdGHoUWFe0h9LNngeADRHxVPHchUVfd0fE88BSSmO0pJRuBb5YrNdNhZtFFXyV0tVh3+OblMaSvwXcATwMvAj0DbUspvTVfj2wEri7ij5qpQtYBtwH3E/pBmBX2fINlI7345RuDJ6TUlpVLBvwuFXhQ8DaYr1zKLux1s8VlD4gnu37pURhMXA8e35YKJPYfXhQ0v6IiFnADSmlyblr6S8i5gEfTSmdlLsWlXgFLA0DxVDQx4Frc9eiPzCApZe5Yox5E6Wx4e9kLkdlHIKQpEy8ApakTIb0hxgTJkxIbW1tdSpFkl6eli9f/lRK6aj+zw8pgNva2li2bFntqpKkYSAiKv41qEMQkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpTJkP6fcJIOfAsXLqS7u3vA5evXrwdg0qRJFZe3t7czf/78utQ23BjA0jDT3d3Nvb95kB0HH1lx+cgXngNgw7Y942HkC0/XtbbhxgCWhqEdBx/J1tfNrbhszKolABWX9y1TbTgGLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZGMBSE1u4cCELFy7MXUbdDZf97K8ldwGSBtbd3Z27hIYYLvvZn1fAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmRjAkpSJASxJmbQ0opOenh4uu+wyLrnkEsaPH9+ILtVkhnIOVGrb3d3NggULuPrqq2lvbx/SNnt6erj44ot57LHHWLhw4a71B+tv/vz5TJkyhSuuuIKHH36YCy64gGOPPZbTTz+dK6+8EoDW1lYAent7mThxIhs3biSlVLGOlpYWent7qzhae673crdq1Sq2bdvGrFmz6tbH2LFj2bJlCwCjRo1ixIgRTJkyhQsvvJArr7yS7du309raynnnncc111yz63yoZ3415Ap40aJF3H///SxevLgR3akJDeUcqNS2q6uLLVu20NXVNeRtLlq0iNWrV7N169bd1h+sv61bt7J69WoWL17MpZdeSkqJhx56iKuuumpXu+3bt7N9+3ZSSmzYsGHA8AX2KXz3Z70DybZt2+reR1/4Arz00ku8+OKLrFmzhq6uLlauXMmaNWtYuXIlXV1du50P9cyvugdwT08Pt912GyklbrvtNnp6eurdpZrMUM6BSm27u7tZu3YtAGvXrqW7u7vqbfb09HDrrbfumu9bv9r+AG655RY2b968a35vIVsvZ555ZsP7bJSzzz47a//lr3XffN/50N3dXdf8qvt3m0WLFrFz504AduzYweLFizn33HPr3a2ayFDOgUptV6xYsVubrq4uZsyYUdU2Fy1axPbt2/dY//rrr6+6v2a4Al23bh0LFiyoyba6u7sZ8dK+fYiMePF5urt/X7Na+uppRjt27KCrq6uu+TXoFXBEfDQilkXEsk2bNg25g6VLl+46gXt7e7n99tuHXqUOaEM5Byq1rXSFUu02ly5dusdz5durpj8NT729vaxdu7au+TXoFXBK6VrgWoCZM2cO+WNz9uzZLFmyhN7eXlpaWjj55JP3oUwdyIZyDlRqu2LFit1Csa2tjRkzZlS1zdmzZ3PzzTfv9lxbW9uQ+msWV199dU22s2DBApY/tHGf1t05+lDaj5tYs1qAut542x8tLS1MnjyZdevW1S2/6j4G3NHRwYgRpW5GjhzJvHnz6t2lmsxQzoFKbTs7O3dr09nZWfU2Ozo6dv1SoXz9ofTXDL9CmDx5cu4S6qb/r1KaxciRI+ns7KxrftU9gMePH8+cOXOICObMmePP0IahoZwDldq2t7fvumpta2ujvb296m2OHz+eU045Zdd83/rV9gdw6qmnMm7cuF3zEbGPR2Lf3XDDDQ3vs1Guu+66rP2Xv9Z9833nQ3t7e13zqyE/Q+vo6OD444/36ncYG8o5UKltZ2cnY8eO3ePqtZptdnR0MG3aNMaMGbPH1e3e+hszZgzTpk1j3rx5XHrppUQExx133G43YVpbW2ltbSUiOProo/cazvt6Jd0MV+D1dtBBB9W9j7Fjx+6aHjVqFKNHj2bq1Kl0dnYyffp0pk6dyvTp0+ns7NztfKhnfsVQflIzc+bMtGzZspoXIamyvl8b1HLMtW8MeOvr5lZcPmbVEoCKy8esWsIf13gMuK8mqO1+NpOIWJ5Smtn/ef8UWZIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKRMDWJIyMYAlKZOW3AVIGlh7e3vuEhpiuOxnfwaw1MTmz5+fu4SGGC772Z9DEJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZm05C5AUuONfOFpxqxaMsCyHoCKy0e+8DQwsZ6lDSsGsDTMtLe373X5+vW9AEyaVCloJw66vqpnAEvDzPz583OXoIJjwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZkYwJKUiQEsSZlESqn6xhGbgEdq0O8E4KkabKcRrLX2DpQ6wVrr4UCpE2pX66tTSkf1f3JIAVwrEbEspTSz4R3vA2utvQOlTrDWejhQ6oT61+oQhCRlYgBLUia5AvjaTP3uC2utvQOlTrDWejhQ6oQ615plDFiS5BCEJGVjAEtSJg0J4Ig4MiJuj4g1xX+P2EvbkRHx64j4cSNqq9D/oLVGxOiI+EVErIiIByLisiaudUpE/G9EPFjUuqAZ6yzafSMinoyI32SocU5E/DYiuiPiogrLIyKuKZbfFxEnNLrGKut8XUTcFRHbIuL8HDWW1TJYrWcUx/K+iLgzIt6Yo86ilsFqPa2o896IWBYRJ9Wk45RS3R/A54GLiumLgM/tpe15wHeAHzeitn2pFQhgXDHdCtwDnNiktb4SOKGYPgRYDUxvtjqLZe8CTgB+0+D6RgK/A44DRgEr+h8jYC5wa/Hanwjck+H1rqbOVwBvAS4Hzm90jUOs9U+AI4rpU3Ic0yHUOo4/3DObAayqRd+NGoI4DVhUTC8CTq/UKCImA6cC1zWorkoGrTWVbC5mW4tHjruZ1dT6RErpV8X074EHgUkNq7Ckqtc/pXQH8HSjiirzVqA7pfRQSukl4LuUai53GrC4eO3vBg6PiFc2W50ppSdTSr8Etje4tv6qqfXOlNIzxezdwOQG19inmlo3pyJ9gbHU6P3eqACemFJ6AkqBQOlTupIvAp8EdjaorkqqqrUYKrkXeBK4PaV0TwNr7FPtcQUgItqAN1O6Ym+kIdWZwSTgsbL5dez5IVVNm3prhhqqNdRaP0LpG0YOVdUaEX8ZEauAW4AP16LjllpsBCAilgJHV1j0qSrXfy/wZEppeUTMqlVdA/S1X7UCpJR2AG+KiMOBH0bEG1JKNR+7rEWtxXbGAf8F/FNK6fla1NZv+zWpM5Oo8Fz/K5xq2tRbM9RQraprjYh3Uwrg2oyrDl1VtaaUfkjpvf4u4N+A2fvbcc0COKU0YDERsTEiXplSeqL42vZkhWbvAP4iIuYCo4FDI+KGlNKZtaqxhrWWb+vZiPgZMAeoeQDXotaIaKUUvt9OKd1U6xprVWdG64ApZfOTgcf3oU29NUMN1aqq1oiYQWnI8ZSUUk+DautvSMc1pXRHRLwmIiaklPbrH+pp1BDEzUBHMd0B/Hf/Bimli1NKk1NKbcDfAj+tR/hWYdBaI+Ko4sqXiBhD6ZNwVcMq/INqag3g68CDKaUrG1hbuUHrzOyXwNSIODYiRlE6/27u1+ZmYF7xa4gTgef6hlWarM5mMWitEfEq4CbgQyml1Rlq7FNNre3Fe4niFzCjgP3/wGjQXcbxwE+ANcV/jyyePwZYUqH9LPL9CmLQWindBf01cB+lq95PN3GtJ1H6OnUfcG/xmNtsdRbzNwJPULqBtA74SANrnEvpFyK/Az5VPHcOcE4xHcCXi+X3AzMzveaD1Xl0ceyeB54tpg9t0lqvA54pOy+X5aizylovBB4o6rwLOKkW/fqnyJKUiX8JJ0mZGMCSlIkBLEmZGMCSlIkBLEmZGMCSlIkBLEmZ/D/SIUpDMrsYdgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(y_pred)\n",
    "plt.title(\"Predicted Loan Propensity\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x = conn, y = y_pred, alpha = 0.3)\n",
    "plt.xlabel(\"Network Degree\")\n",
    "plt.ylabel(\"Loan\")\n",
    "plt.title(\"Predicted Values\")\n",
    "plt.ylim([-0.5, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAd2UlEQVR4nO3de5hcdZ3n8fenu/qSdDppQmIICZCIQYkMQWlhHUWZcUTAUbzMOOCFi+4g+4gz6o6PzPjo4s6z62VllVlwMtFFYbzAsKLiDAo+46jMKEoHCVeBAAJNQuhAOul0+lbd3/3jnMZKpbupQJ+u7vw+r+epp+v8zq9+9e3T1fWpc6lzFBGYmVm6GupdgJmZ1ZeDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwMwscQ4Cs+dA0sWSvl7AuOdK+vfpHtdsKg4Cm5Mk/UTSDkktNfafkTdYSSsklSUdOcG870j6fNE1mO0vB4HNOZJWAScBAby5rsVUiYjHgX8F3lPZLmkxcDpwZT3qMpuKg8DmorOBW4CvAedUzpB0mKTrJPVIekrSZZKOBtYDr5S0W1Jv3vcnkv5zxWP3WmuQdKmkxyTtkrRR0kk11nclVUEAnAncHRF3SrpI0oOS+iTdI+mtEw0iaZWkkFSqaKuu+b2S7s3Xjm6UdETeLklfkPSkpJ2S7pB0TI31W2IcBDYXnQ18I7+9QdIyAEmNwD8DjwCrgBXA1RFxL3AB8IuIWBARHTU+z63AccBi4JvAtZJaa3jcd4Alkl5d0fYe4Kr8/oNkazSLgE8BX5e0vMaaniHpLcDfAG8DlgI3A9/KZ58CvAY4CugA/gx4an+fw9LgILA5JX9zPQL4p4jYSPam+s589gnAocBHI6I/IgYj4jnvF4iIr0fEUxFRjohLgBbgxTU8bgC4liywkLQGOJ4sTIiIayNiS0SMRcQ1wAN57fvr/cCnI+LeiCgD/xM4Ll8rGAHagZcAyvtsfQ7PYQlwENhccw5wU0Rsz6e/ye82Dx0GPJK/KT5vkv5rvtllZ745aRGwpMaHXwm8I1+DeA/ww4h4Mh/3bEm3S+rNxz1mP8atdARwacU4TwMCVkTEj4HLgMuBbZI2SFr4HJ7DEuAgsDlD0jzgHcBrJT0h6Qngw8A6SeuAx4DDK7epV5joNLv9wPyK6UMqnusk4GP58x2Ub07aSfZG+6wi4mayTTFnAO8m3yyUf1r/MnAhcHA+7l2TjNuf/5ywRrLf9/0R0VFxmxcRP89r+LuIOB54Kdkmoo/WUrulx0Fgc8lbgFFgLdm2++OAo8m2jZ8N/ArYCnxGUpukVkmvyh+7DVgpqblivNuBt0maL+lFwPsq5rUDZaAHKEn6JLC/n6ivAj5Lto3++3lbG1ko9QBIOo9sjWAfEdEDPA68W1KjpPcClYelrgf+WtJL87EWSfrT/P4rJJ0oqYksUAbJlp3ZPhwENpecA3w1Ih6NiCfGb2SbQN5F9qn6TcCLgEeBbrKdpAA/Bu4GnpA0vlnpC8AwWUhcSbbzedyNwA+A+8l2Pg+SfQLfH1cBhwPXRMQQQETcA1wC/CJ/3t8D/mOKMf6c7JP8U2Sf7H8+PiMivkMWNFdL2kW2ZnFaPnsh2ZrHjrz+pwB/h8EmJF+YxswsbV4jMDNLnIPAzCxxDgIzs8Q5CMzMEjfR8daz2pIlS2LVqlX1LsPMbE7ZuHHj9ohYOtG8ORcEq1atoqurq95lmJnNKZIemWyeNw2ZmSXOQWBmljgHgZlZ4hwEZmaJcxCYmSWusKOGJF0B/DHwZETsc3ZFSQIuJbuO6x7g3Ii4rYhaVl30L0UMm5xWYLQBRsYm79PUAItbYOcIDFdcFaClJKRgflMjrc0lDm5r4WUr29mya4RtfYMsai1xzKGLWHlwG4vbmlm3soPlHfOetaatvQNs6u7l6f7h/XrcZGPs2jPMYzv20D88yrKFrZx+zHLWHX7Qfo1nNtcUuUbwNeDUKeafBqzJb+cDf19EEQ6B6TPI1CFAPn/bAAyWs3Mtj+W3gXKwZwS27xllcLjMEzsH+Pqtj/PAk7vomNdE945BvrdpK1t29DMwPMqP7tnG1t6BKZ9ra+8AP7pnGwPDoyxZ0FLz4yYbY/fgCD+4axv3b9tNe0uJ3UNlNvzsYTY9uqPm8czmosKCICJ+RnbFpMmcAVwVmVuAjudy3VabvarPa9uQ33YMjDI0GpQaxFP9I/QNjbJwXjMLWhu5+cGnaW9tor21xKbu3inH39TdS3trifbWJhqkmh832RgbH+2lo62JjvktbO8f5qD5LXS0lbjhLl/h0Q5s9dxHsIK9z+/enbftQ9L5krokdfX09MxIcTb9pOyCAWMBQ6NjNDfASDkYLo/R2ABtzSV27RkGoK2lxNP9w1OO93T/MG0te2/drOVxk43Ru2eYtqZGmhrFwHC26rOotYltuwb347c0m3vqGQQTXZpvwosjRMSGiOiMiM6lSyf8hrTNARHZH7hB0NLYwPAYNJVEc6mB0THoHy6zcH52AbH+oTKL25qnHG9xWzP9Q3tfnriWx002Rsf8ZvpHRhkZDeY1Z/8aOwdHWLawdT9+S7O5p55B0E12sfFxK4EtdarFClCd9OP7Cw6a10hLoyiPBQe3NdHe0siugWF2D45y0pGL6RscoW+wzLqVHVOOv25lB32DZfoGRxiLqPlxk41x/OEd9PaP0LtniCVtzezYM0Rvf5nTj/EWSzuw1TMIrgfOVuY/ATsjYto3xv72M2+c7iGT1Up2VNBUmhpg2TxoLWVBML5fYF5JzG+CJfOzo4YOWTSPd79iBWtesJDegRFWHtTKGeuWc+hBbcxrbuT1a5c969E/yzvm8fq1y5jX3Mj23UM1P26yMRa0NnHaMcs4atkC+obKLGgpcf5rVvuoITvgFXn46LeAk4ElkrqB/wY0AUTEeuAGskNHN5MdPnpeUbU4DA5cyzvm7ffhokWMYTaXFRYEEXHWs8wP4ANFPb+ZmdXG3yw2M0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxBUaBJJOlXSfpM2SLppg/iJJ35e0SdLdks4rsh4zM9tXYUEgqRG4HDgNWAucJWltVbcPAPdExDrgZOASSc1F1WRmZvsqco3gBGBzRDwUEcPA1cAZVX0CaJckYAHwNFAusCYzM6tSZBCsAB6rmO7O2ypdBhwNbAHuBP4yIsaqB5J0vqQuSV09PT1F1WtmlqQig0ATtEXV9BuA24FDgeOAyyQt3OdBERsiojMiOpcuXTr9lZqZJazIIOgGDquYXkn2yb/SecB1kdkMPAy8pMCazMysSpFBcCuwRtLqfAfwmcD1VX0eBV4HIGkZ8GLgoQJrMjOzKqWiBo6IsqQLgRuBRuCKiLhb0gX5/PXA3wJfk3Qn2aakj0XE9qJqMjOzfRUWBAARcQNwQ1Xb+or7W4BTiqzBzMym5m8Wm5klzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpY4B4GZWeIcBGZmiXMQmJklzkFgZpa4QoNA0qmS7pO0WdJFk/Q5WdLtku6W9NMi6zEzs32VihpYUiNwOfB6oBu4VdL1EXFPRZ8O4EvAqRHxqKQXFFWPmZlNrMg1ghOAzRHxUEQMA1cDZ1T1eSdwXUQ8ChARTxZYj5mZTaDIIFgBPFYx3Z23VToKOEjSTyRtlHT2RANJOl9Sl6Sunp6egso1M0tTkUGgCdqiaroEHA+8EXgD8AlJR+3zoIgNEdEZEZ1Lly6d/krNzBJW2D4CsjWAwyqmVwJbJuizPSL6gX5JPwPWAfcXWJeZmVUoco3gVmCNpNWSmoEzgeur+nwPOElSSdJ84ETg3gJrMjOzKoWtEUREWdKFwI1AI3BFRNwt6YJ8/vqIuFfSD4E7gDHgKxFxV1E1mZnZvhRRvdl+duvs7Iyurq56l2FmNqdI2hgRnRPN8zeLzcwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0tcTUEg6W2SHpC0U9IuSX2SdhVdnJmZFa/WL5R9DnhTRPhbv2ZmB5haNw1tcwiYmR2Yal0j6JJ0DfBdYGi8MSKuK6QqMzObMbUGwUJgD3BKRVsADgIzszmupiCIiPOKLsTMzOqjpiCQ1Aq8D3gp0DreHhHvLaguMzObIbXuLP5H4BCyq4j9lOwiM31FFWVmZjOn1iB4UUR8AuiPiCvJLi35e8WVZWZmM6XWIBjJf/ZKOgZYBKwqpCIzM5tRtR41tEHSQcAnyC43uSC/b2Zmc1ytRw19Jb/7U+CFxZVjZmYzrdZzDS2S9AVJXfnt85IWFV2cmZkVr9Z9BFcAu4B35Lc+4KtFFWVmZjOn1n0ER0bE2yumPyXp9iIKMjOzmVXrGsGApFePT0h6FTBQTElmZjaTal0juAC4qmK/wA7gnGJKMjOzmVTrUUObgHWSFubTuyR9CLijyOLMzKx4+3WpyojYFRHjVyb7SAH1mJnZDHs+1yzWtFVhZmZ183yCIKatCjMzq5sp9xFI6mPiN3wB8wqpyMzMZtSUQRAR7TNViJmZ1cfz2TRkZmYHAAeBmVniCg0CSadKuk/SZkkXTdHvFZJGJf1JkfWYmdm+CgsCSY3A5cBpwFrgLElrJ+n3WeDGomoxM7PJFblGcAKwOSIeiohh4GrgjAn6fRD4NvBkgbWYmdkkigyCFcBjFdPdedszJK0A3gqsn2ogSeePXwuhp6dn2gs1M0tZkUEw0TePq7+T8EXgYxExOtVAEbEhIjojonPp0qXTVqCZmdV+9tHnohs4rGJ6JbClqk8ncLUkgCXA6ZLKEfHdAusyM7MKRQbBrcAaSauBx4EzgXdWdoiI1eP3JX0N+GeHgJnZzCosCCKiLOlCsqOBGoErIuJuSRfk86fcL2BmZjOjyDUCIuIG4IaqtgkDICLOLbIWMzObmL9ZbGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniHARmZolzEJiZJc5BYGaWOAeBmVniCg0CSadKuk/SZkkXTTD/XZLuyG8/l7SuyHrMzGxfhQWBpEbgcuA0YC1wlqS1Vd0eBl4bEccCfwtsKKoeMzObWJFrBCcAmyPioYgYBq4GzqjsEBE/j4gd+eQtwMoC6zEzswkUGQQrgMcqprvztsm8D/jBRDMknS+pS1JXT0/PNJZoZmZFBoEmaIsJO0p/QBYEH5tofkRsiIjOiOhcunTpNJZoZmalAsfuBg6rmF4JbKnuJOlY4CvAaRHxVIH1mJnZBIpcI7gVWCNptaRm4Ezg+soOkg4HrgPeExH3F1iLmZlNorA1gogoS7oQuBFoBK6IiLslXZDPXw98EjgY+JIkgHJEdBZVk5mZ7UsRE262n7U6Ozujq6ur3mWYmc0pkjZO9kHb3yw2M0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxDkIzMwS5yAwM0ucg8DMLHEOAjOzxJWKHFzSqcClQCPwlYj4TNV85fNPB/YA50bEbdNdx6qL/mW6h7Q6GP/U0twArS2NLGptQmNlHt1ZZqyiT0tJtLWUWFAKHu8rMzK297yxsSACGhuzfocvauLRnSP0D5WBoK2lRGtTI62lBg7taGXxglaWLWzlRUvms3n7HrbtGuSRnt08tL2f4dGs/8lrFnPwwvls2zWIAoIAibbmRg47aD4L5zezuK2ZdSs7WN4xD4CtvQNs6u7l6f5hFrc1s3xhK1t3DT4zXdm3FtXjFflcqZhqmR5IdSgipm2wvQaWGoH7gdcD3cCtwFkRcU9Fn9OBD5IFwYnApRFx4lTjdnZ2RldXV811OAQOTK2C4eCZAKgkoJZXdbOgnI9RAppKMFDO5i1qEeUxMQqceMQiWppL3Nndx7GHLaJn5x5u7+5DggXNYmQMBkeCow+Zz9HLO/jlwzuQgrXL23mqf4ThcvDGYw9haXsrfYNlXr92GQA/umcb7a0l2lpKPL5jgK7f7uD4VR2sPGg+/UPlZ/rW8g+/tXdgr/EqHz/dz5WKqZbpTC6n6apD0saI6JxoXpGbhk4ANkfEQxExDFwNnFHV5wzgqsjcAnRIWl5gTXaAGJwkBKC2EIC9g6QMjIxm/xANwM6hYF5zidZSA/c+sZuevmHaWht5sm+Ie57YTWMDNDc2UA4hiQbBg9sHePCpPSycX2JhazO/2babjvktdLQ1sfHRXtpbm2hvLbGpu5dN3b20t5Zob22iQaJn9yAdbSW29w3TIO3VtxbV4xX5XKmYapkeaHUUGQQrgMcqprvztv3tg6TzJXVJ6urp6Zn2Qs0ARiNbm2hQNt3YIJobRf/IGLuHyrQ3N9I/NMLIaFBqyN78y2NBeSwoNcDIaNA/NEJrqZHmkugfGqWpUbQ1NdK7ZxiAtpYST/cP83T/MG0tv9sy2zdYZlFrE31DI8+0jfetRfV4RT5XKqZapgdaHUUGgSZoq/6wVksfImJDRHRGROfSpUunpTizao3KXnxj+StwdCyyfQBNDSxoKdE3PEpbSxNNjaI8FowFlBpEqUGUx8je9FuaGCyPMlwO2loas3AYGaVjfjMA/UNlFrdl+wuyfRKZ9tYSOwdHaG9peqZtvG8tqscr8rlSMdUyPdDqKDIIuoHDKqZXAlueQx+zfbRq8hfvRJ8uJtJcMUYJaGrMNhWNke0jGBguM1ge4+hDFrC0vZn+wVFe0N7C2kMWMDoGw6NjlBREZKFw5JJ5HHnwfHbtKbNrcJiXLFtA754hevtHOP7wDvoGR+gbLLNuZQfrVnbQN1imb3CEsQiWLmilt7/MkvZmxiL26luL6vGKfK5UTLVMD7Q6itxZXCLbWfw64HGyncXvjIi7K/q8EbiQ3+0s/ruIOGGqcfd3ZzF4h/GBwkcNTc1HDU2/A+mooal2FhcWBPkTnw58kezw0Ssi4n9IugAgItbnh49eBpxKdvjoeREx5bv8cwkCM7PUTRUEhX6PICJuAG6oaltfcT+ADxRZg5mZTc3fLDYzS5yDwMwscQ4CM7PEOQjMzBJX6FFDRZDUAzzyHB++BNg+jeUUaa7U6jqn31yp1XVOr6LrPCIiJvxG7pwLgudDUtdkh0/NNnOlVtc5/eZKra5zetWzTm8aMjNLnIPAzCxxqQXBhnoXsB/mSq2uc/rNlVpd5/SqW51J7SMwM7N9pbZGYGZmVRwEZmaJSyYIJJ0q6T5JmyVdVO96xkk6TNK/SbpX0t2S/jJvv1jS45Juz2+nz4JafyvpzryerrxtsaQfSXog/3nQLKjzxRXL7XZJuyR9aDYsU0lXSHpS0l0VbZMuQ0l/nb9m75P0hjrX+b8k/UbSHZK+I6kjb18laaBiua6ffOQZq3XSv/UsW6bXVNT4W0m35+0zu0wj4oC/kZ0G+0HghUAzsAlYW++68tqWAy/P77eTXcNhLXAx8Ff1rq+q1t8CS6raPgdclN+/CPhsveuc4G//BHDEbFimwGuAlwN3PdsyzF8Hm4AWYHX+Gm6sY52nAKX8/mcr6lxV2W+WLNMJ/9azbZlWzb8E+GQ9lmkqawQnAJsj4qGIGAauBs6oc00ARMTWiLgtv98H3MsE122exc4ArszvXwm8pY61TOR1wIMR8Vy/jT6tIuJnwNNVzZMtwzOAqyNiKCIeBjaTvZbrUmdE3BQR49dMvIXsioJ1N8kyncysWqbj8muzvAP41kzUUi2VIFgBPFYx3c0sfLOVtAp4GfDLvOnCfDX8itmwyYXskr43Sdoo6fy8bVlEbIUs1IAX1K26iZ3J3v9cs22ZwuTLcDa/bt8L/KBierWkX0v6qaST6lVUlYn+1rN1mZ4EbIuIByraZmyZphIEE13GdlYdNytpAfBt4EMRsQv4e+BI4DhgK9lqY729KiJeDpwGfEDSa+pd0FQkNQNvBq7Nm2bjMp3KrHzdSvo4UAa+kTdtBQ6PiJcBHwG+KWlhverLTfa3npXLFDiLvT+wzOgyTSUIuoHDKqZXAlvqVMs+JDWRhcA3IuI6gIjYFhGjETEGfJkZWn2dSkRsyX8+CXyHrKZtkpYD5D+frF+F+zgNuC0itsHsXKa5yZbhrHvdSjoH+GPgXZFvzM43szyV399Itt39qPpVOeXfejYu0xLwNuCa8baZXqapBMGtwBpJq/NPiWcC19e5JuCZbYP/F7g3Iv53Rfvyim5vBe6qfuxMktQmqX38PtmOw7vIluM5ebdzgO/Vp8IJ7fUpa7Yt0wqTLcPrgTMltUhaDawBflWH+oDsyDvgY8CbI2JPRftSSY35/ReS1flQfap8pqbJ/tazapnm/gj4TUR0jzfM+DKdqb3S9b4Bp5MdkfMg8PF611NR16vJVk3vAG7Pb6cD/wjcmbdfDyyvc50vJDvaYhNw9/gyBA4G/hV4IP+5uN7LNK9rPvAUsKiire7LlCyYtgIjZJ9O3zfVMgQ+nr9m7wNOq3Odm8m2r4+/Ttfnfd+evyY2AbcBb5oFy3TSv/VsWqZ5+9eAC6r6zugy9SkmzMwSl8qmITMzm4SDwMwscQ4CM7PEOQjMzBLnIDAzS5yDwOYUSSHpkorpv5J08bM85mRJv19ALedKuqyGPj35qQIekHRjEbWYPR8OAptrhoC3SVqyH485GZjWN9/826C1uiYiXhYRa4DPANdJOnoaamh8vmOYgYPA5p4y2bVdP1w9I/825rcl3ZrfXpWfyO8C4MP5ed1fK+khZTokjY2fM0nSzZJepOz6AN/NT1h2i6Rj8/kXS9og6SbgqqrnfqOkXzxbQEXEv+X1n58/7khJP8xP5HezpJdUtN+S/x7/XdLuvP1kZdev+CZwp6RGZdcJuDWv9/0VNX20ov1Tz21xWwr251ON2WxxOXCHpM9VtV8KfCEi/l3S4cCNEXG0sot67I6IzwNIGr/mw2pgI3CSpF8CKyNis6T/A/w6It4i6Q/J3vSPy5/jeODVETEg6dx8vLeSnRjs9IjYUUP9twHjb9gbyL5V+oCkE4EvAX+Y/y6XRsS3JF1Q9fgTgGMi4mFlZ4HdGRGvkNQC/EceVGvy2wlkJ1q7XtJrIjsVstleHAQ250TELklXAX8BDFTM+iNgbXb6JgAWjp8fqcrNZBcJWQ18Gvhz4Kdk56SC7LQfb8+f68eSDpa0KJ93fURUPucfAJ3AKZGdNbYWgmfOOPv7wLUVNbfkP1/J765L8E3g8xWP/1Vk59KH7JxPx0r6k3x6EVkAnJLffp23L8jbHQS2DweBzVVfJPtk/dWKtgbglVVv1FS8yY67mWxz0aHAJ4GPku1HGH+TnOpUxf1V7Q+RnYfpKKCrxtpfRnYBogagNyKOe5b+1SprEPDBiLixsoOySzB+OiL+YT/HtgR5H4HNSRHxNPBPZCcYG3cTcOH4hKTxN9g+ssuAjvsl2SfxsYgYJDuB2vvJAgKyQHhXPsbJwPYpPu0/QnYK4askvfTZ6pb0WrL9A1/Ox3xY0p/m8yRpXd71FvK1ErKz5U7mRuC/KDuVOZKOys8OeyPw3nytA0krJM22iwbZLOEgsLnsEqBy5+xfAJ35ztF7yD71A3wfeGu+s/ikiBgiO4vmLfn8m8mC4s58+uLxcciO8hk/RfSEIuI+suC4VtKRE3T5s/y57wf+Bnh7RNybz3sX8D5J42d1Hb+E6oeAj0j6Fdl1rXdO8vRfAe4BblN2UfR/ILuu8E1km5R+IelO4P+xdxiaPcNnHzWbhSTNBwYiIiSdCZwVEbPiOtt24PE+ArPZ6XjgMmU7OHrJrhFsVgivEZiZJc77CMzMEucgMDNLnIPAzCxxDgIzs8Q5CMzMEvf/AVU3E6kfGV7aAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(x = conn, y = y, alpha = 0.3)\n",
    "plt.xlabel(\"Network Degree\")\n",
    "plt.ylabel(\"Loan\")\n",
    "plt.title(\"Actual Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35266241672365084\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.334e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 9 iterations, i.e. alpha=4.263e-05, with an active set of 9 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 11 iterations, i.e. alpha=2.359e-05, with an active set of 11 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 12 iterations, i.e. alpha=2.139e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.561e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=1.341e-05, with an active set of 12 regressors, and the smallest cholesky pivot element being 3.495e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 15 iterations, i.e. alpha=9.736e-06, with an active set of 13 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 16 iterations, i.e. alpha=7.339e-06, with an active set of 14 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:597: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 17 iterations, alpha=6.522e-06, previous alpha=4.867e-06, with an active set of 14 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.584e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 5 iterations, i.e. alpha=7.479e-05, with an active set of 5 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 6 iterations, i.e. alpha=6.901e-05, with an active set of 6 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=5.784e-05, with an active set of 7 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 8 iterations, i.e. alpha=5.129e-05, with an active set of 8 regressors, and the smallest cholesky pivot element being 1.490e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:597: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 13 iterations, alpha=5.004e-05, previous alpha=3.078e-05, with an active set of 10 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 3 iterations, i.e. alpha=1.195e-04, with an active set of 3 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.153e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 5.771e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:597: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 8 iterations, alpha=5.661e-05, previous alpha=5.637e-05, with an active set of 7 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 4 iterations, i.e. alpha=1.185e-04, with an active set of 4 regressors, and the smallest cholesky pivot element being 3.650e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 7 iterations, i.e. alpha=4.826e-05, with an active set of 5 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:570: ConvergenceWarning: Regressors in active set degenerate. Dropping a regressor, after 14 iterations, i.e. alpha=2.129e-05, with an active set of 8 regressors, and the smallest cholesky pivot element being 3.332e-08. Reduce max_iter or increase eps parameters.\n",
      "  warnings.warn('Regressors in active set degenerate. '\n",
      "C:\\Users\\bengbengbb\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_least_angle.py:597: ConvergenceWarning: Early stopping the lars path, as the residues are small and the current value of alpha is no longer well controlled. 19 iterations, alpha=1.500e-05, previous alpha=1.025e-05, with an active set of 12 regressors.\n",
      "  warnings.warn('Early stopping the lars path, as the residues '\n"
     ]
    }
   ],
   "source": [
    "naive = pd.concat([dhat, Xd2], axis = 1)\n",
    "lasso_naive = ls_mod.fit(naive, y)\n",
    "pred_naive = ls_fit.predict(naive)\n",
    "print(np.sqrt(mean_squared_error(y, pred_naive)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00024953132940558386\n",
      "0.00026639871322527565\n"
     ]
    }
   ],
   "source": [
    "se_boot = []\n",
    "for i in range(0, 1000):\n",
    "    sample_index = np.random.choice(range(0, len(y)), len(y))\n",
    "    x_samples = x.iloc[sample_index]\n",
    "    y_samples = y[sample_index]\n",
    "    OLS_boot = linear_model.OLS(y_samples, x_samples).fit()\n",
    "   \n",
    "    se_boot.append(OLS_boot.bse['connections'])\n",
    "\n",
    "se_boot.sort()\n",
    "print(se_boot[24])\n",
    "print(se_boot[974])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
